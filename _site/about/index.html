<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>about me</title><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="thekingofcool&apos;s qqzone" /><link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico" />
  <link rel="stylesheet" href="/assets/css/main.css" />

  <link href="https://cdn.jsdelivr.net/gh/gangdong/gangdong.github.io@dev/assets/css/syntax_monokai.css" rel="stylesheet"/>
</head><body a="auto">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/"><-</a><h1></h1>

<h1 id="edward-chen">Edward Chen</h1>

<table>
  <tbody>
    <tr>
      <td>ðŸ“ž 188-8387-8352</td>
      <td>ðŸ“§ sayhi@thekingof.cool</td>
    </tr>
    <tr>
      <td><a href="https://linkedin.com/in/thekingofcool">LinkedIn</a></td>
      <td><a href="https://github.com/thekingofcool">GitHub</a></td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="professional-summary">Professional Summary</h2>
<p>Big Data Engineer with over 6 years of experience in data development, skilled in cloud technologies like AWS and proficient in Python, R, and Scala. Expertise in Airflow and the Apache Hadoop/Spark ecosystem (Hadoop, Hive, Spark, HDFS/S3). Previously a Structural Engineer with a background in Civil Engineering from Chongqing University.</p>

<p>I like sports. Boxing, swimming, and running. Make sports a daily habit.</p>

<hr />

<h2 id="professional-experience">Professional Experience</h2>

<h3 id="big-data-engineer">Big Data Engineer</h3>
<p><strong>Nike (Contract)</strong><br />
<em>Mar 2019 - Present</em></p>

<ul>
  <li>Led and contributed to the design, development, and deployment of various big data projects.</li>
  <li>Automated data delivery, validation, and task monitoring processes.</li>
  <li>Migrated data platforms to enhance efficiency.</li>
</ul>

<h3 id="big-data-engineer-1">Big Data Engineer</h3>
<p><strong>Shanghai Shouyi Information Technology</strong><br />
<em>Aug 2018 - Feb 2019</em></p>

<ul>
  <li>Developed the companyâ€™s big data architecture and implemented stream processing frameworks.</li>
  <li>Conducted offline data analysis, managed risk control, and validated abnormal user data.</li>
  <li>Researched and integrated new technologies, and documented technical processes.</li>
</ul>

<h3 id="construction-engineer">Construction Engineer</h3>
<p><strong>China State Construction Third Engineering Bureau</strong><br />
<em>Jul 2016 - Nov 2017</em></p>

<ul>
  <li>Reviewed construction drawings, drafted construction plans, and inspected construction sites.</li>
  <li>Received first prize in the 2017 Xiamen QC Group Activity.</li>
</ul>

<hr />

<h2 id="education">Education</h2>
<p><strong>Chongqing University</strong><br />
Bachelorâ€™s in Civil Engineering (2012 - 2016)</p>

<hr />

<h2 id="certifications--training">Certifications &amp; Training</h2>
<ul>
  <li><a href="https://www.credly.com/users/thekingofcool/badges">Snowflake Certified Data Engineer</a></li>
</ul>

<hr />

<h2 id="projects">Projects</h2>
<h3 id="nike-consumer-promise-review">Nike Consumer Promise Review</h3>

<ul>
  <li><strong>Overview:</strong> Supported the backend data development for tracking key Consumer Promise metrics across the Digital Supply Chain, including service, shipment, convenience, sustainability, and cost metrics.</li>
  <li><strong>Tech Stack:</strong> Spark, Hive/Presto, Python, Airflow</li>
  <li><strong>Role:</strong> Develop ETL processes and prepare Presto tables for reporting.</li>
</ul>

<h3 id="gc-inbound-transportation">GC Inbound Transportation</h3>

<ul>
  <li><strong>Overview:</strong> Managed the inbound shipment process from factories to the GC Central DC, optimizing transport modes and tracking shipment stages to ensure timely inventory deployment.</li>
  <li><strong>Tech Stack:</strong> Spark, Python, EMR, Snowflake, Box, Airflow</li>
  <li><strong>Role:</strong> Develop ETL processes and generate data to Box and Snowflake for use in front-end reports.</li>
</ul>

<h3 id="nike-united-intelligent-inventory">Nike United Intelligent Inventory</h3>

<ul>
  <li><strong>Overview:</strong> Created a system for real-time data aggregation and demand forecasting to optimize inventory replenishment based on machine learning algorithms.</li>
  <li><strong>Tech Stack:</strong> Spark, Python, S3, EMR, Snowflake, Airflow</li>
  <li><strong>Role:</strong> Collect and cleanse data to form model feature tables, maintaine various dimensional information, and monitore data quality.</li>
</ul>

<h3 id="cryptocurrency-transaction-data-analysis-platform">Cryptocurrency Transaction Data Analysis Platform</h3>

<ul>
  <li><strong>Overview:</strong> Built a big data platform for real-time and offline analysis of cryptocurrency transactions, including user token holdings, abnormal transaction detection, and average transaction interval calculations.</li>
  <li><strong>Tech Stack:</strong> Flume, Kafka, Hadoop, Structured Streaming, Aurora</li>
  <li><strong>Role:</strong> Consume Kafka topics via Structured Streaming to process user asset changes and transaction logs, meeting business data requirements.</li>
</ul>

<hr />

<h2 id="additional-information">Additional Information</h2>
<ul>
  <li><strong>Languages:</strong> Fluent in English</li>
  <li><strong>Interests:</strong> Building my body in physical world and upgrading skills in cyber world</li>
</ul>

      </div>
    </main>
  </body>
</html>