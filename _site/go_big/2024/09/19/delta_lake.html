<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Hands on Delta Lake</title><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="thekingofcool&apos;s website" /><link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico" />
  <link rel="stylesheet" href="/assets/css/main.css" />

  <link href="https://cdn.jsdelivr.net/gh/gangdong/gangdong.github.io@dev/assets/css/syntax_monokai.css" rel="stylesheet"/>
</head><body a="dark">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/"><-</a><article>
  <p class="post-meta">
    <time datetime="2024-09-19 00:00:00 +0800">2024-09-19</time>
  </p>
  
  <h1>Hands on Delta Lake</h1>

  <h3 id="what-is-delta-lake">What is Delta Lake</h3>
<p><a href="https://delta.io/">Delta Lake</a> 是一个开源的数据湖存储层 (lakehouse storage layer) 技术，它利用基于文件的事务日志 (file-based transaction log) 扩展了 <a href="https://parquet.apache.org/">Parquet</a> 数据文件，以实现 ACID 事务和可扩展的元数据处理。Delta Lake 与 Apache Spark API 完全兼容，专为与 Structured Streaming 集成而开发，可以很方便地对 batch &amp; streaming 数据进行处理。</p>

<p>Delta Lake 的主要优势是它对大规模数据处理的可靠性和一致性，同时提供了类似于传统数据库的事务功能。在使用过程中可以通过 Spark SQL 来读取、写入和管理 Delta Lake 中的数据。下面将这些功能一一演示。</p>

<h3 id="how-to-use-delta-lake">How to Use Delta Lake</h3>
<h4 id="install-delta-packege">Install Delta Packege</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>delta-spark<span class="o">==</span>2.1.0
</code></pre></div></div>

<h4 id="load-delta-related-jars-from-maven-repo">load delta related jars from maven repo</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pyspark <span class="nt">--packages</span> io.delta:delta-core_2.12:2.1.0 <span class="se">\</span>
<span class="nt">--conf</span> <span class="s2">"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension"</span> <span class="se">\</span>
<span class="nt">--conf</span> <span class="s2">"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"</span> <span class="se">\</span>
<span class="nt">--conf</span> <span class="s2">"hive.tez.input.format=io.delta.hive.HiveInputFormat"</span>
</code></pre></div></div>

<h4 id="set-up-a-python-project">Set up a Python Project</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">delta</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">builder</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">DeltaDemo</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.extensions</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">io.delta.sql.DeltaSparkSessionExtension</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.catalog.spark_catalog</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">org.apache.spark.sql.delta.catalog.DeltaCatalog</span><span class="sh">"</span><span class="p">)</span>

<span class="n">spark</span> <span class="o">=</span> <span class="nf">configure_spark_with_delta_pip</span><span class="p">(</span><span class="n">builder</span><span class="p">).</span><span class="nf">getOrCreate</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="create-a-table">Create a Table</h4>
<p><strong>1. Using Spark SQL DDL</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
create or replace table {your_database}.delta_demo(
    id int, 
    firstName string, 
    middleName string, 
    lastName string, 
    gender string, 
    birthDate date, 
    ssn string, 
    salary int)
using delta 
location </span><span class="sh">'</span><span class="s">s3://{S3_BUCKET}/delta_demo</span><span class="sh">'</span><span class="s">;
</span><span class="sh">"""</span><span class="p">)</span>

<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"</span><span class="s">drop table {your_database}.delta_demo</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>2. Using Exsiting Spark Dataframe and change the format to delta</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="append-data">Append Data</h4>
<p><strong>Write data from existing Spark Dataframe</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">date</span>

<span class="n">schema</span> <span class="o">=</span> <span class="nc">StructType</span><span class="p">([</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">,</span> <span class="nc">IntegerType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">firstName</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">middleName</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">lastName</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">birthDate</span><span class="sh">"</span><span class="p">,</span> <span class="nc">DateType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">ssn</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">salary</span><span class="sh">"</span><span class="p">,</span> <span class="nc">IntegerType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
  <span class="p">(</span><span class="mi">9999998</span><span class="p">,</span> <span class="sh">'</span><span class="s">Billy</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Tommie</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Luppitt</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1992-09-17</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">953-38-9452</span><span class="sh">'</span><span class="p">,</span> <span class="mi">55250</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">9999999</span><span class="p">,</span> <span class="sh">'</span><span class="s">Elias</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Cyril</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Leadbetter</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1984-05-22</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">906-51-2137</span><span class="sh">'</span><span class="p">,</span> <span class="mi">48500</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">10000000</span><span class="p">,</span> <span class="sh">'</span><span class="s">Joshua</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Chas</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Broggio</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1968-07-22</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">988-61-6247</span><span class="sh">'</span><span class="p">,</span> <span class="mi">90000</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">20000001</span><span class="p">,</span> <span class="sh">'</span><span class="s">John</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="sh">'</span><span class="s">Doe</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1978-01-14</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">345-67-8901</span><span class="sh">'</span><span class="p">,</span> <span class="mi">55500</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">20000002</span><span class="p">,</span> <span class="sh">'</span><span class="s">Mary</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="sh">'</span><span class="s">Smith</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1982-10-29</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">456-78-9012</span><span class="sh">'</span><span class="p">,</span> <span class="mi">98250</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">20000003</span><span class="p">,</span> <span class="sh">'</span><span class="s">Jane</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="sh">'</span><span class="s">Doe</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1981-06-25</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">567-89-0123</span><span class="sh">'</span><span class="p">,</span> <span class="mi">89900</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">data_insert</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
<span class="n">data_insert</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">append</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">{S3_BUCKET}/delta_demo</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="read-table">Read Table</h4>
<p><strong>1. Read Delta table name</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">delta_demo_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">table</span><span class="p">(</span><span class="sh">"</span><span class="s">{your_database}.delta_demo</span><span class="sh">"</span><span class="p">)</span>
<span class="n">delta_demo_df</span><span class="p">.</span><span class="nf">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>firstName</th>
      <th>middleName</th>
      <th>lastName</th>
      <th>gender</th>
      <th>birthDate</th>
      <th>ssn</th>
      <th style="text-align: left">salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>9999998</td>
      <td>Billy</td>
      <td>Tommie</td>
      <td>Luppitt</td>
      <td>M</td>
      <td>1992-09-17</td>
      <td>953-38-9452</td>
      <td style="text-align: left">55250</td>
    </tr>
    <tr>
      <td>9999999</td>
      <td>Elias</td>
      <td>Cyril</td>
      <td>Leadbetter</td>
      <td>M</td>
      <td>1984-05-22</td>
      <td>906-51-2137</td>
      <td style="text-align: left">48500</td>
    </tr>
    <tr>
      <td>20000002</td>
      <td>Mary</td>
      <td> </td>
      <td>Smith</td>
      <td>F</td>
      <td>1982-10-29</td>
      <td>456-78-9012</td>
      <td style="text-align: left">98250</td>
    </tr>
    <tr>
      <td>20000003</td>
      <td>Jane</td>
      <td> </td>
      <td>Doe</td>
      <td>F</td>
      <td>1981-06-25</td>
      <td>567-89-0123</td>
      <td style="text-align: left">89900</td>
    </tr>
    <tr>
      <td>10000000</td>
      <td>Joshua</td>
      <td>Chas</td>
      <td>Broggio</td>
      <td>M</td>
      <td>1968-07-22</td>
      <td>988-61-6247</td>
      <td style="text-align: left">90000</td>
    </tr>
    <tr>
      <td>20000001</td>
      <td>John</td>
      <td> </td>
      <td>Doe</td>
      <td>M</td>
      <td>1978-01-14</td>
      <td>345-67-8901</td>
      <td style="text-align: left">55500</td>
    </tr>
  </tbody>
</table>

<p><strong>2. Read Delta table by specifying the path to the file</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="update-table">Update Table</h4>
<p><strong>1. Using Spark SQL DML</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
UPDATE {your_database}.delta_demo SET gender = </span><span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="s"> WHERE gender = </span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="s">
</span><span class="sh">"""</span><span class="p">)</span>
<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
UPDATE {your_database}.delta_demo SET gender = </span><span class="sh">'</span><span class="s">Male</span><span class="sh">'</span><span class="s"> WHERE gender = </span><span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="s">
</span><span class="sh">"""</span><span class="p">)</span>
<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
CREATE OR REPLACE TEMP VIEW upsert_view (
  id, firstName, middleName, lastName, gender, birthDate, ssn, salary
) AS VALUES
  (9999998, </span><span class="sh">'</span><span class="s">Billy</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Tommie</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Luppitt</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">1992-09-17</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">953-38-9452</span><span class="sh">'</span><span class="s">, 55250),
  (20000003, </span><span class="sh">'</span><span class="s">Jane</span><span class="sh">'</span><span class="s">, </span><span class="sh">''</span><span class="s">, </span><span class="sh">'</span><span class="s">Doe</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">1981-06-25</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">567-89-0123</span><span class="sh">'</span><span class="s">, 89900)
</span><span class="sh">"""</span><span class="p">)</span>
<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
MERGE INTO {your_database}.delta_demo demo
USING upsert_view upsert
ON demo.id = upsert.id
WHEN MATCHED THEN UPDATE SET *
WHEN NOT MATCHED THEN INSERT *
</span><span class="sh">"""</span><span class="p">)</span>
<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
DELETE FROM {your_database}.delta_demo WHERE birthDate &lt; </span><span class="sh">'</span><span class="s">1980-01-01</span><span class="sh">'</span><span class="s">
</span><span class="sh">"""</span><span class="p">)</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>firstName</th>
      <th>middleName</th>
      <th>lastName</th>
      <th>gender</th>
      <th>birthDate</th>
      <th>ssn</th>
      <th style="text-align: left">salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>9999998</td>
      <td>Billy</td>
      <td>Tommie</td>
      <td>Luppitt</td>
      <td>M</td>
      <td>1992-09-17</td>
      <td>953-38-9452</td>
      <td style="text-align: left">55250</td>
    </tr>
    <tr>
      <td>9999999</td>
      <td>Elias</td>
      <td>Cyril</td>
      <td>Leadbetter</td>
      <td>Male</td>
      <td>1984-05-22</td>
      <td>906-51-2137</td>
      <td style="text-align: left">48500</td>
    </tr>
    <tr>
      <td>20000002</td>
      <td>Mary</td>
      <td> </td>
      <td>Smith</td>
      <td>Female</td>
      <td>1982-10-29</td>
      <td>456-78-9012</td>
      <td style="text-align: left">98250</td>
    </tr>
    <tr>
      <td>20000003</td>
      <td>Jane</td>
      <td> </td>
      <td>Doe</td>
      <td>F</td>
      <td>1981-06-25</td>
      <td>567-89-0123</td>
      <td style="text-align: left">89900</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>注：
Delta Lake 为了解决数据的一致性和可靠性，引入了事务日志和元数据管理来实现 ACID 事务。</p>

  <p>Delta Lake 的物理构成主要是两部分：</p>
  <ol>
    <li>以 Parquet 格式存储在文件系统的数据文件，任何数据操作，数据文件只增不减；</li>
    <li>在数据文件的同级目录下，有一个文件夹专门存放 Json 格式的事务日志，它用来记录所有对数据的操作，每一次操作都会生成一个日志文件，记录这次操作的详细信息。</li>
  </ol>

  <p>基于以上架构，在每次读取 Delta Lake 数据时，会自动根据事务日志生成一个数据快照，并将该快照的结果返回成 Dataframe。</p>
</blockquote>

<p><strong>2. Using Delta Lake API</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">delta.tables</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">pyspark.sql.functions</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">deltaTable</span> <span class="o">=</span> <span class="n">DeltaTable</span><span class="p">.</span><span class="nf">forPath</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Update every even value by adding 100 to it
</span><span class="n">deltaTable</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span>
  <span class="n">condition</span> <span class="o">=</span> <span class="nf">expr</span><span class="p">(</span><span class="sh">"</span><span class="s">id % 2 == 0</span><span class="sh">"</span><span class="p">),</span>
  <span class="nb">set</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="nf">expr</span><span class="p">(</span><span class="sh">"</span><span class="s">id + 100</span><span class="sh">"</span><span class="p">)</span> <span class="p">})</span>

<span class="c1"># Delete every even value
</span><span class="n">deltaTable</span><span class="p">.</span><span class="nf">delete</span><span class="p">(</span><span class="n">condition</span> <span class="o">=</span> <span class="nf">expr</span><span class="p">(</span><span class="sh">"</span><span class="s">id % 2 == 0</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># Upsert (merge) new data
</span><span class="n">newData</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">deltaTable</span><span class="p">.</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">oldData</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">merge</span><span class="p">(</span>
    <span class="n">newData</span><span class="p">.</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">newData</span><span class="sh">"</span><span class="p">),</span>
    <span class="sh">"</span><span class="s">oldData.id = newData.id</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">whenMatchedUpdate</span><span class="p">(</span><span class="nb">set</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">newData.id</span><span class="sh">"</span><span class="p">)</span> <span class="p">})</span> \
  <span class="p">.</span><span class="nf">whenNotMatchedInsert</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">newData.id</span><span class="sh">"</span><span class="p">)</span> <span class="p">})</span> \
  <span class="p">.</span><span class="nf">execute</span><span class="p">()</span>

<span class="n">deltaTable</span><span class="p">.</span><span class="nf">toDF</span><span class="p">().</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>
<h4 id="read-older-versions-of-data">Read older versions of data</h4>
<p><strong>Delta Lake 提供方式查询历次数据更改后的数据版本的快照</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df1</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">versionAsOf</span><span class="sh">"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>

<span class="n">df2</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">timestampAsOf</span><span class="sh">"</span><span class="p">,</span> <span class="n">timestamp_string</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Data Retention</strong>
为了访问先前版本的 Delta table 数据，必须完整地保留数据文件和事务日志。默认情况下，数据文件不会自动被清除，表的历史快照会被保留 30 天。</p>
<ol>
  <li>清除数据文件，执行 <a href="https://docs.delta.io/2.1.0/delta-utility.html#-delta-vacuum">VACUUM</a>
```sql
– vacuum files not required by versions older than the default retention period
VACUUM {your_database}.delta_demo</li>
</ol>

<p>– vacuum files in path-based table
VACUUM ‘/data/events’
VACUUM delta.<code class="language-plaintext highlighter-rouge">/data/events/</code></p>

<p>– vacuum files not required by versions more than 100 hours old
VACUUM delta.<code class="language-plaintext highlighter-rouge">/data/events/</code> RETAIN 100 HOURS</p>

<p>– do dry run to get the list of files to be deleted
VACUUM {your_database}.delta_demo DRY RUN</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
2. 改变数据留存时间，改变 [Table properties](https://docs.delta.io/2.1.0/delta-batch.html#-table-properties)
```sql
--controls how long the history for a table is kept. The default is interval 30 days.
ALTER TABLE {your_database}.delta_demo SET TBLPROPERTIES ('delta.logRetentionDuration' = 'interval &lt;interval&gt;');
</code></pre></div></div>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">--To access historical data even if you run VACUUM on the Delta table, This setting may cause your storage costs to go up.</span>
<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="p">{</span><span class="n">your_database</span><span class="p">}.</span><span class="n">delta_demo</span> <span class="k">SET</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="s1">'delta.deletedFileRetentionDuration'</span> <span class="o">=</span> <span class="s1">'interval &lt;interval&gt;'</span><span class="p">);</span>
</code></pre></div></div>

<h4 id="write-a-stream-of-data-to-a-table">Write a stream of data to a table</h4>
<p><strong>支持将 Structured Streaming 的流式数据集写入 Delta table</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">streamingDf</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">rate</span><span class="sh">"</span><span class="p">).</span><span class="nf">load</span><span class="p">()</span>

<span class="n">stream</span> <span class="o">=</span> <span class="n">streamingDf</span> \
  <span class="p">.</span><span class="nf">selectExpr</span><span class="p">(</span><span class="sh">"</span><span class="s">value as id</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">writeStream</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">checkpointLocation</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">/tmp/checkpoint</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">start</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="read-delta-table-as-a-streaming-source">Read Delta table as a streaming source</h4>
<p><strong>将 Delta 表的更新读进流式数据中</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stream2</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">writeStream</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">console</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">start</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="hive-insert-overwrite-vs-delta-lake-update">Hive Insert Overwrite VS Delta Lake Update</h3>
<h4 id="hive-insert-overwrite">Hive Insert Overwrite</h4>
<p><strong>Advantages:</strong></p>
<ol>
  <li><strong>Simplicity</strong>: Hive 的 overwrite 功能简单易用，特别是在需要完全替换表中数据时；</li>
  <li><strong>Compatibility</strong>: Hive 与 Hadoop 生态系统紧密集成，与各种基于 Hadoop 的工具和框架兼容；</li>
  <li><strong>Flexibility</strong>: 可以用于 overwrite 整个表或特定分区，提供数据管理的灵活性。</li>
</ol>

<p><strong>Disadvantages:</strong></p>
<ol>
  <li><strong>Limited Update Support</strong>: 缺乏细粒度更新的能力（如更新特定的行或列），对于细粒度更新的情景效率低下；</li>
  <li><strong>Resource-Intensive</strong>: overwrite 大表涉及删除现有数据并写入新数据，消耗大量资源，影响性能和存储利用率；</li>
  <li><strong>No Transaction Support</strong>: Hive 的 overwrite 操作不支持 ACID 事务，不利于在并发环境中保持数据完整性。</li>
</ol>

<h4 id="delta-lake-update">Delta Lake Update</h4>
<p><strong>Advantages:</strong></p>
<ol>
  <li><strong>ACID Transactions</strong>: Delta Lake 提供完整的 ACID 事务，确保在并发读写操作中数据的完整性和一致性；</li>
  <li><strong>Fine-Grained Updates</strong>: 支持细粒度更新，允许更高效和有针对性的数据操作；</li>
  <li><strong>Schema Evolution</strong>: Delta Lake 支持模式演化，允许对表 Schema 进行更改而无需重写整个数据集；</li>
  <li><strong>Optimized Performance</strong>: Delta Lake 的优化存储格式和事务功能有助于提高大规模数据集处理性能。</li>
</ol>

<p><strong>Disadvantages:</strong></p>
<ol>
  <li><strong>Dependency on Spark</strong>: Delta Lake 与 Apache Spark 紧密集成，受限于不能直接与其他数据处理框架一起使用；</li>
  <li><strong>Limited Compatibility</strong>: Delta Lake 与 Hive 的集成存在限制，主要在元数据管理方面；</li>
  <li><strong>Complexity</strong>: ACID 事务和模式演化功能增加了复杂性，需要更深入地理解底层存储和处理机制。</li>
</ol>

<h4 id="summary">Summary</h4>
<p>总之，Hive 的 overwrite 功能提供了简单性和兼容性，但缺乏细粒度更新支持和 ACID 事务；Delta Lake提供 ACID 事务、精细更新、模式演化和优化性能，但依赖于 Spark，与其他框架的兼容性有限。</p>

<p>具体的选择取决于用例的要求，包括对事务支持、精细更新和现有技术栈的需求。</p>

<h3 id="delta-lake-on-unstructured-and-semi-structured-data">Delta Lake on Unstructured and Semi-structured Data</h3>
<p>依照同样的原理，Delta Lake 也可以用来处理 Json、XML、Avro 等半结构化数据，以及文本、图像、音频、视频等非结构化的数据。</p>

<p><strong>1. 以 Json 数据为例，将半结构化对象存入 Delta Table</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="c1"># 创建 Spark Session
</span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span> \
    <span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">DeltaLakeExample</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.extensions</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">io.delta.sql.DeltaSparkSessionExtension</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.catalog.spark_catalog</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">org.apache.spark.sql.delta.catalog.DeltaCatalog</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">getOrCreate</span><span class="p">()</span>

<span class="c1"># 读取 JSON 数据
</span><span class="n">json_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">json</span><span class="p">(</span><span class="sh">"</span><span class="s">/path/to/json/files</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 将 JSON 数据写入 Delta Lake 表
</span><span class="n">json_df</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">append</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table-json</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 读取 Delta Lake 表中的 JSON 数据
</span><span class="n">delta_json_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table-json</span><span class="sh">"</span><span class="p">)</span>
<span class="n">delta_json_df</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><strong>2. 以文本数据为例，将非结构化对象存入 Delta Table</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="n">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># 创建 Spark Session
</span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span> \
    <span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">DeltaLakeExample</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.extensions</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">io.delta.sql.DeltaSparkSessionExtension</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.catalog.spark_catalog</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">org.apache.spark.sql.delta.catalog.DeltaCatalog</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">getOrCreate</span><span class="p">()</span>

<span class="c1"># 定义 schema
</span><span class="n">schema</span> <span class="o">=</span> <span class="nc">StructType</span><span class="p">([</span>
    <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">,</span> <span class="nc">IntegerType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
    <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># 创建数据
</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">This is a sample text.</span><span class="sh">"</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="sh">"</span><span class="s">Another example of text data.</span><span class="sh">"</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># 创建 DataFrame
</span><span class="n">text_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>

<span class="c1"># 将文本数据写入 Delta Lake 表
</span><span class="n">text_df</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">append</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table-text</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 读取 Delta Lake 表中的文本数据
</span><span class="n">delta_text_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table-text</span><span class="sh">"</span><span class="p">)</span>
<span class="n">delta_text_df</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p>To be continued…</p>

</article>
      </div>
    </main>
  </body>
</html>