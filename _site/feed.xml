<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-10-21T17:23:40+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">thekingofcool’s cyber space</title><entry><title type="html">The Keyboard-Only Revolution: Best Practices of Neovim</title><link href="http://localhost:4000/blog/2024/10/21/neovim.html" rel="alternate" type="text/html" title="The Keyboard-Only Revolution: Best Practices of Neovim" /><published>2024-10-21T00:00:00+08:00</published><updated>2024-10-21T00:00:00+08:00</updated><id>http://localhost:4000/blog/2024/10/21/neovim</id><content type="html" xml:base="http://localhost:4000/blog/2024/10/21/neovim.html"><![CDATA[<h3 id="why-keyboard-only">Why Keyboard-Only</h3>
<ol>
  <li>鼠标操作形成不了肌肉记忆，效率严重不足；</li>
  <li>写代码过程中，鼠标操作属于上下文切换，手腕的移动、光标的对准、操作模型的切换都带来更大的耗时；</li>
  <li>鼠标操作的可靠性和准确性不如键盘操作；</li>
  <li>鼠标操作在写代码过程中是一种打断心流的操作；</li>
  <li>鼠标操作的诞生是为了服务 GUI 时代，天生不适合文本编辑任务。</li>
</ol>

<p>综上所述，摆脱鼠标是提升代码效率很重要的一步。开门见山，今天带来的解决方案是 <a href="https://neovim.io/">Neovim</a>。</p>

<h3 id="download-neovim">Download Neovim</h3>
<ul>
  <li><strong>Windows</strong>: Install with Windows Package Manager <a href="https://learn.microsoft.com/en-us/windows/package-manager/winget/">Winget</a>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>winget <span class="nb">install </span>Neovim.Neovim
</code></pre></div>    </div>
  </li>
  <li><strong>Linux</strong>: Install in Debian
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>neovim
</code></pre></div>    </div>
  </li>
  <li><strong>MacOS</strong>: Install with Homebrew
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>neovim
</code></pre></div>    </div>
  </li>
</ul>

<p>Check Installation:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvim <span class="nt">--version</span>
</code></pre></div></div>

<h3 id="set-up-lazyvim">Set up <a href="http://www.lazyvim.org/">LazyVim</a></h3>
<p><strong>Clone LazyVim Starter</strong></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Windows</span>
git clone https://github.com/LazyVim/starter <span class="nv">$env</span>:LOCALAPPDATA<span class="se">\n</span>vim

<span class="c"># Linux / MacOS</span>
git clone https://github.com/LazyVim/starter ~/.config/nvim
</code></pre></div></div>

<p><strong>Remove the <code class="language-plaintext highlighter-rouge">.git</code> folder, so you can add it to your own repo later</strong></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Windows</span>
Remove-Item <span class="nv">$env</span>:LOCALAPPDATA<span class="se">\n</span>vim<span class="se">\.</span>git <span class="nt">-Recurse</span> <span class="nt">-Force</span>

<span class="c"># Linux / MacOS</span>
<span class="nb">rm</span> <span class="nt">-rf</span> ~/.config/nvim/.git
</code></pre></div></div>

<p><strong>Start Neovim!</strong></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvim
</code></pre></div></div>

<h3 id="types-of-shortcuts">Types of Shortcuts</h3>
<p><strong>1. 文本操作</strong>
文本的插入、删除、替换、选取、跳转；
<strong>2. 编辑器功能</strong>
文件间的跳转，函数或变量名的搜索、替换，错误修复，代码生成。</p>

<h3 id="how-to-vim">How to Vim</h3>
<p>学习 Vim 的文本操作只需要记住一个公式：</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;number&gt;&lt;command&gt;&lt;text object or motion&gt;
</code></pre></div></div>
<ul>
  <li>number: 操作次数；</li>
  <li>command: 操作行为；</li>
  <li>text object or motion: 操作对象或操作距离</li>
</ul>

<p>Some practical learning websites:
<a href="https://openvim.com/">Open Vim</a>; <a href="https://vim-adventures.com/">Vim Adventures</a>; <a href="https://www.vim.org/docs.php">Vim Documentation</a></p>

<p>To Be Continued…</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[Why Keyboard-Only 鼠标操作形成不了肌肉记忆，效率严重不足； 写代码过程中，鼠标操作属于上下文切换，手腕的移动、光标的对准、操作模型的切换都带来更大的耗时； 鼠标操作的可靠性和准确性不如键盘操作； 鼠标操作在写代码过程中是一种打断心流的操作； 鼠标操作的诞生是为了服务 GUI 时代，天生不适合文本编辑任务。]]></summary></entry><entry><title type="html">一片红布，崔健</title><link href="http://localhost:4000/daguguguji/2024/10/20/a_piece_of_red_cloth.html" rel="alternate" type="text/html" title="一片红布，崔健" /><published>2024-10-20T00:00:00+08:00</published><updated>2024-10-20T00:00:00+08:00</updated><id>http://localhost:4000/daguguguji/2024/10/20/a_piece_of_red_cloth</id><content type="html" xml:base="http://localhost:4000/daguguguji/2024/10/20/a_piece_of_red_cloth.html"><![CDATA[<p>火车上意外碰见老板，我俩面对面下铺，神了，</p>

<p>老板说，张伟，你好，我说，老板你好，没话说了，过了会我说，老板去哪，老板说，去南京，有个大活动，</p>

<p>最近没见你么，我说，这么忙</p>

<p>瞎几把忙，老板说，你去哪</p>

<p>我回家，我说，你不在单位没人管了，呆着无聊，回家过节去</p>

<p>老板说，哈哈哈，你们这些人，我没说话，老板心很高，想干大事，单位上没有共鸣，这两年一直在外面参加各种活动，对我们很失望，单位里也各忙各的，心照不宣</p>

<p>你们这些人，没有信念，老板说，一下子把话题拔高了，严肃起来，什么信念，我说，我们也就混个日子</p>

<p>没点想干大事的想法吗，老板说</p>

<p>有倒是有，不过什么是大事，我的大事跟领导的可能不一样，我说</p>

<p>所以我就不爱在单位呆，没有共鸣，讲不到一起去，老板说，我们这代人，都有一种干大事的情怀，要开创新局面，为人类奋斗，改变世界，我可以改变世界～改变自己～改变隔膜～改变小气～老板唱</p>

<p>这种情怀确实没有，我说，太大了，我感受不到</p>

<p>你的情怀是什么！老板发问</p>

<p>我的情怀就是改变自己生活，活的更好，我说</p>

<p>怎样算更好，现在不好吗，老板说</p>

<p>不太好，我说，至今没用上新款粪叉</p>

<p>唱出来！老板说，用一首歌唱，你选哪一首</p>

<p>一年过了又是新的一年～每一年都曾经是新的一年～在每个新的一年三百六十五天～我们都每天进步一点点～我唱到</p>

<p>你这个格局就太小，知道为啥我不爱在单位呆吗，没有共同语言，在外面参加各种大活动，真的别开生面，大家都很上进，有一群人努着劲，要把你们生活变好，我在南京就很有共鸣，老板说，发达地区不一样</p>

<p>你也快退了吧，我说，退了心态就平和了，可能是退休前综合症，很多人都有</p>

<p>退了怎么了，退了一样干大事，老板说，我干的事退不退都一样，退了更自由，手脚放的更开，我有信心</p>

<p>支持老板！我说，你们位置高，肯定思考不一样，我理解不了，站的高才能看的远，位置决定眼界，我支持你</p>

<p>咱们喝点呗，老板说，喝啥，我说，还能喝啥，酒呗，老板从铺下面拉出一个纸盒，拿出一个双胞胎，两个半斤装的青稞，整两口，不然没事干，那就整呗，我说，不喝干撒着，喝呗，酒一拿出来，旁边两个学生模样的年轻人也兴奋了，要求加入，大学生吗，我说，就是，学生说</p>

<p>你哪的，我说，虎台的，一个学生说，我城东的，另一个说</p>

<p>你回民吗，我说，不是，汉民，学生说，现在搬到新区去了，我们这还有两个酒呢，一起喝</p>

<p>遭就喝呗，我说，服务员！我叫住一个列车员，给我们找几个杯子，撒杯子，没有杯子，列车员说，喝酒的杯子没有吗，我说，到餐车找上几个去，列车员白眼一翻，奥呦，到哪找杯子去呢，餐车那要到餐车吃饭才有杯子，不能带到车厢里，列车员娓娓道来，你们要喝到餐车喝去，我火一下上来了，跳到列车员前面把路一拦，姑娘，我说，听我的，赶紧去找几个杯子去，别把你个家耽误哈，你知道这里坐的多大的领导吗，我说，杯子找不来把喝酒耽误哈，你吃不住，我娓娓道来，列车员不知道啥情况，往格挡里张望，老板似笑非笑的看着她，高深莫测，列车员挖不清了，不知道该怎么办，这时后面一个人跳出来，推了列车员一把，小王赶紧去，拿几个杯子去，就说我要的，再拿点瓜子花生，赶紧去，推了列车员一把，是列车长，胳膊上戴着列车长的牌子，列车员赶紧去了，列车长坐下来说，听了半天了，都是干大事的，我也陪你们喝两口</p>

<p>你们上班喝着没事吗，老板问</p>

<p>球上的事，有撒事，卧铺车没人管，我们是下等人，领导不爱组织不管，喝呗，列车长说</p>

<p>遭就喝呗，杯子拿来了，列车员把瓜子花生摆上，酒倒给，各就各位，老板举杯说，先整一个，大家举杯整了，咣叽一下，稳当，青稞还是稳当，酒倒满了列车长举杯，遭再整一个，大家举杯，稳当，喝完把酒倒上，领导说，我现在真是，不开心，实话说，领导自己喝了一口，想干的事情没人理解，总以为我要怎么样，我操心的其实是大家，想为人类谋福祉，奈何明月照沟渠，领导喝了一口</p>

<p>我也不开心，列车长说，火车火车开了一辈子，把自己开到绿皮车上了，上不了高铁，办公楼也进不去，说是个列车长，狗毛啊，高铁上不去说撒着，系统里没人理家里也说不上话，破烦，列车长说，儿子大了就是个白眼狼，跟爹不亲，我活明白了，但是又不明白，不知道自己活了个撒照，列车长喝了一大口</p>

<p>你莱张伟，老板说，你阿木着，开心不开心</p>

<p>不开心，我说，但是也不难过，就这求样子呗，我又没个级别，混日子呗，我喝了一口</p>

<p>你一天单位上不见人，贼的很，老板说，心眼子有呢</p>

<p>我心思不在单位上，我说，我主要经营互联网路，最近我在研究一种温柔哭泣课程，哭的好的话就红了，怎么个哭泣法，老板说，就是每天在网路上哭惨，一天哭25次，激起网友的同情心，我说，激起一种广泛的共鸣，到时候就可以骗钱了，我说，现在网友可有钱了，重要的是要激起他们母爱，我现在有几百万粉丝，基础有了，只差母爱</p>

<p>有印象！一个学生说，你难道是那个时尚博主，鸡士球，是的，是我，我说，正是在下，我是鸡士球</p>

<p>最近老看你微博哭泣，原来是有这个打算，一个学生说，好使吗，是真哭吗</p>

<p>必须真哭，我说，我每条微博都是真哭，真听真看真感觉，必须真哭才发微博，不然不是欺骗粉丝吗，我说，必须有感而发，真哭了才发微博，以情动人，将心比心，这是我的底线</p>

<p>真不容易！两个学生站起来惊呼，没想到现在还有这么用心经营微博的博主，喝一个球哥，学生们举杯，敬佩你</p>

<p>不敢当，我端起来酎了一个，我们时尚博主都是有担当，起码不会骗人，我说，体力好，真心换温柔，很坦然</p>

<p>你们呢，怎么样，老板问学生，感觉怎么样，这个时代，还不错，一个学生说，都挺好的</p>

<p>具体哪里好呢，老板问，有没有什么意见，对这个社会</p>

<p>暂时没有，一个学生说，家里还行，也不缺钱，我在西安上学，房子家里也给买了，去年涨的一塌糊涂，赚翻了，以后自己不住卖了也是一笔钱</p>

<p>我在成都上学，另一个学生说，挺好的，西宁房子好几套，成都也有一套，现在做新媒体，运营美食账号，很火爆，开挂了，学生说</p>

<p>我在西安运营美食账号，火的很，另一个学生说，开挂了，营销不断，我们想了想，西部餐饮发达，有钱没钱饭总要吃，什么行业都有起伏，餐饮没有，只要美国不打过来我们美食公共号永远好</p>

<p>去过美国吗，老板问</p>

<p>没有，学生说，没去过，另一个学生说</p>

<p>想不想去美国，我问</p>

<p>没啥特别想去的，学生说，没什么特别感觉，另一个学生说，我对美国没有概念</p>

<p>做新媒体不去北京吗，我说，不去北京做什么媒体，资源都在北京</p>

<p>不爱去，一个学生说，不爱听北京话，听着心里抓摘，</p>

<p>搞互联网的哪有北京人，我说，都是老乡，老外地</p>

<p>反正不爱听，一个学生说，外地人说北京口音才可怕，想捅一刀</p>

<p>去过南方吗，我问，深圳上海怎么样，</p>

<p>不爱去，一个学生说，以后西宁发展好了，准备回西宁，抓面吃不上酸汤喝不上心里抓摘</p>

<p>酒赶紧喝给，老板说，在铺下面摸了几下又摸出一个双胞胎，你们喝着，我去上厕所，我们这个老板眼界高，我说，想干大事，心气特别高，想成就伟大事业，你们听着可能觉得可笑，可人家就是这么想的，我说，眼界不一样，在西宁埋没了，胸怀人类，我们为老板喝一个，我主动举杯，温柔的人应该被温柔对待，老板不值得
谁说不是呢，列车长说，我何曾不想，我也有梦想，可惜没资源，想火箭上天，没燃料助推不是偏闲传着吗，列车长喝了一杯，你说你们家里，列车长问学生，家里都是单位上的吧，就是的，一个学生说，我爸省委的，小官，他爸水电的，我们是亲戚，我妈是他二姨，遭就说呗，列车长说，我有个关系我也坐办公室了，还在绿皮车跑撒着，列车长又端了一个</p>

<p>老板要死了，我说，你们知道吗，他不想活了，想办法解脱，说不定现在正想办法着，我说，不会从窗子跳下去吧，列车长说，胡大诶，遭把我害哈了，他爬不出去，肚子太大，我说，他这个人就是心气太高，有点眼高手低，气顺不过来，不会吃那个什么药把自己毒死吧，一个学生说，最近毒狗很厉害，那个叫什么，不太可能，我说，他应该用一种传统的方法，自缢，前几天看一个日本电影，吊死很简单，用绳子把自己挂在门把手上就可以，我说，根本不用上天花板找地方，很古典，正说着老板回来了，你们喝着阿木着，再整个酒呗，老板说</p>

<p>一个学生说我这有呢，从铺下面摸索半天，掏出个天佑德，还有两瓶，学生说，我们准备路上喝的，喝一个喝一个，老板把杯子倒满，举杯到列车长面前，整给一个呗，老板说，如果让你现在唱一首歌，你唱什么，列车长举杯一饮而尽，我为祖国献石油！列车长箭步长江，做出向阳而生的动作，哪里有石油～哪里就是我的家～我们家也是老革命，有传统的，奉献过，好的很，老板说，谁有蓝牙音响，放个音乐，都没有蓝牙音响，老板外放起来，崔健，北京故事，唱了半天，还是唱不干净这城市的痛苦，老板跟着唱，可痛苦越多越愿意想象，谁还听崔健啊，我说，不听崔健听谁，老板说，如果让你唱一首歌，你唱谁，说不上爱别说谎～就一点喜欢，说不上恨别纠缠～别装作感叹，我唱起来，台湾女歌手，忘了叫啥，very good！老板说，喝一个，你在网上叫什么，什么球？鸡士球，我说，祝你成功，鸡士球，老板说，谢谢，我说，我有信心，第一个目标是骗个粪叉s，碰杯，接下来是学生，喝一个，老板说，如果让你唱一首歌，你唱什么，遭再唱撒呢，你不喝，我不喝，青海文化谁传播，直接喝呗，球哥，咱们喝一个，一个学生说，祝你哭泣事业有成，祝你被温柔对待，谢谢，我说，你也一样，好好做新媒体，年轻人，祝你有灿烂的前程 ，祝你有情人终成眷属祝你在尘世获得幸福，车长来喝一个，祝你坐上办公室，</p>

<p>突然一场运动来到了我的身边，像是一场革命把我的生活改变，一个姑娘带着爱情来到了我眼前，我站起来，头有点晕，眼前突然出现一个屁股，一个饱满的，浑圆的，似乎也富有弹性的屁股，红裤衩，超市款式，如此立体出现在眼前，是中铺的女的，背靠着我，不知怎么的红色的裙子撩起来，露出屁股，我突然有一个大胆的想法，伟大事业，要干大事，不如今天就干个大事，我把头埋进去，埋到这个屁股里，会发生什么也不想了，还能怎样，酒喝到这个地步，就干个大事，管他稳当不稳定当，这并不是坏事，我把头凑过去闻了闻，肉的味道，女的突然抬头了，咋了喝多了吗，女的问，脸看不清，有些胖，四肢也很壮硕，有点晕，我说，那你把头埋进来休息休息，女的说，把屁股一撅，靠一靠，我愣住了，不知道这是一个什么邀请，过气的绿皮卧铺车，不被理解的领导，绝望列车长，过气时尚博主，新媒体从业人员，巨大屁股就在眼前，立体，不容多想，今天就干个大事，我猛的把头埋进去，好像离家许久的人回到老家院子，院里落叶堆积，女人迅速把裙子扬起，盖住我的头，四周暗下来，声场细节逐渐丰富，空间有了一种立体感，音乐与态度在裙子外吵杂，而眼前一片红色，是的，一片红布，崔健，我狠狠的朝前拱了一下，鼻子缓冲到一个隆起的洼地，温暖，潮湿，想起李红旗的诗，看，不远处那如河岸般隆起的肉，年轻人，那就是x</p>]]></content><author><name></name></author><category term="daguguguji" /><summary type="html"><![CDATA[火车上意外碰见老板，我俩面对面下铺，神了，]]></summary></entry><entry><title type="html">My Investment Strategy</title><link href="http://localhost:4000/blog/2024/10/20/my_investment_strategy.html" rel="alternate" type="text/html" title="My Investment Strategy" /><published>2024-10-20T00:00:00+08:00</published><updated>2024-10-20T00:00:00+08:00</updated><id>http://localhost:4000/blog/2024/10/20/my_investment_strategy</id><content type="html" xml:base="http://localhost:4000/blog/2024/10/20/my_investment_strategy.html"><![CDATA[<h3 id="前言">前言</h3>
<p>不知不觉，差不多半年多没有股票操作了，加密货币上一次操作也是一年以前。在这个时间点，整理一下我的投资策略。</p>

<p>今天在网上看到一个<a href="https://www.reddit.com/r/ValueInvesting/comments/1g7857u/how_many_companies_you_keep_track_of/">讨论</a>，问大家日常追踪的公司有多少家。我的观点就是尽可能少地集中关注几个熟悉的领域或公司，如果实在觉得没精力或没天赋，直接把钱放在标普 500 或纳斯达克 100 指数基金里。我有四分之一多的仓位放在 VOO（标普500追踪基金），个股我长期关注了 Apple(APPL) 和 Unity(U)，Unity 整体仓位占比超过一半。加密货币我的仓位主要在两部分，Dogecoin(Doge) 和 Swarm(BZZ)。</p>

<h3 id="为什么不投资-a-股">为什么不投资 A 股</h3>
<p>无论从市场成熟度、信息透明度来说，A 股现阶段都不具备正规投资属性。作为普通人，玩不来，所以不去凑热闹。</p>

<h3 id="voo">VOO</h3>
<p><a href="https://investor.vanguard.com/investment-products/etfs/profile/voo">VOO</a> 是由 Vanguard 推出的投资 S&amp;P 500 Index 基金，费率 0.03%，投资着 500 家美国最大的公司。对于标普 500，可以在支付宝全球投资里找到对应的指数基金，或者 FOF(fund of funds)，也可以在美股中找到相应基金，综合对比交易费率、管理费率、交易时效性及潜在兑付风险选择标的。至于是定投还是一次性投资，在指数上，我的观点是除非美国经济基本面出现重大风险，在任何时间点，都可以把闲钱一次性投进去，从某种意义上说，做多标普 500 就是做多人类科技，也就是做多人类未来。</p>

<h3 id="apple">Apple</h3>
<p><a href="https://investor.apple.com/investor-relations/default.aspx">Apple</a> 是目前全球最大的公司，但它的优势其实并不在市场规模、科技能力、利润率或现金储备，而是这家公司的价值观，它基于以人为本，对用户健康、隐私的在乎构建它的生态系统，用户的信任是苹果这家公司最大的护城河。另外苹果的出现首次模糊了时尚的财富边界，不论你是亿万富翁，或是还没毕业的学生，手里拿的 iPhone 都是同一流水线生产，它用全新的方式定义了审美。所以在我看来，只要前述现象没有产生质的变化，就可以放心做苹果的股东。</p>

<h3 id="unity">Unity</h3>
<p><a href="https://investors.unity.com/overview/default.aspx">Unity</a> 是我除了 Apple 以外唯一持有的个股，这家公司经历过元宇宙概念时期的风口浪尖，被称为“元宇宙的卖铲人”，它的游戏引擎业务至今在同行业尤其是手游、虚拟现实开发占据绝对的领先位置，但存在的问题是公司从未扭亏为盈，一年多前，公司管理层尝试增加引擎收入，做了一系列错误的决定，导致股票一路下跌，今年 5 月公司任命了 Matt Bromberg 作为新的 CEO，由此带来一系列大刀阔斧的改革，证明了新 CEO 的能力和 Unity 的潜力。从各方面看，Unity 都走在了正确的道路上。更新了收费政策、推出了更稳定、更强大的新引擎版本，注重客户交流，替换了公司财务官。我有幸在公司低谷建仓完成，这支成长型股票，在未来风险收益指数可观。有 Apple 和 VOO 的压舱，期望 Unity 能起到撬动高收益的作用。同时 Unity 除了游戏引擎业务，重要的业务版图还有工业设计、建筑设计、电影制作等，掌握 Unity 开发是一个很有意思的技能，学习 Unity 也在我的学习清单上。</p>

<h3 id="doge">Doge</h3>
<p>加密货币在我看来是社会变革的一次很好尝试，它对于权威系统的颠覆性和具有的生命力让它的未来有很大的想象空间。<a href="https://dogecoin.com/">Dogecoin</a> 是 2013 年因一个玩笑而诞生，其出现也具备某种宿命性，Why so serious。另外很重要的一点，这个加密货币从某种角度看已经和 Elon Musk 强绑定，未来只要 Musk 还在，故事就有充足的讲法。因此，留在牌桌上，为什么不呢？</p>

<h3 id="ethereum-swarm">Ethereum Swarm</h3>
<p><a href="https://www.ethswarm.org/">Swarm</a> 是以太坊区块链上一个去中心化存储的解决方案，最开始由 Ethereum Foundation 孵化，2021 年主网上线，从 EF 独立出来由 Swarm Foundation 开发维护，这个组织成员具有极客精神，做的事情是真正的去中心化。但目前从结果上看还没有被市场接受，也许这个项目会石沉大海，也许不会。不管怎样，投资是一件为自己的认知和价值观买单的事情，观察后续如何发展。</p>

<h3 id="eth--pol">ETH &amp; POL</h3>
<p>另外我还有少量的 <a href="https://ethereum.org/">ETH</a> 和 <a href="https://polygon.technology/">Matic</a>，用来体验这些生态上一些有趣的项目。</p>

<h3 id="最后">最后</h3>
<p>做任何一笔投资前需要弄清楚的三件事：你投的是什么，你为什么买它，以及在什么情况下你会出售它。</p>

<p>永远不要买你不明白的东西，永远不要花费超出你能承受损失数额的钱来买任何东西。</p>

<p>我的逻辑是，事前做充分的调查，在理智的情况下买入并持有，在 FOMO(fear of missing out) 情绪到来时分批降低仓位。其余时间不过多关注，让时间成为你的朋友。投资乃至做任何决定都是为了给自己和家人以更好的生活，平衡好个人精力、家庭风险和生活本身永远是最重要的事。</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[前言 不知不觉，差不多半年多没有股票操作了，加密货币上一次操作也是一年以前。在这个时间点，整理一下我的投资策略。]]></summary></entry><entry><title type="html">伟大的工程要建三百年</title><link href="http://localhost:4000/daguguguji/2024/10/20/the_great_project_of_300_years.html" rel="alternate" type="text/html" title="伟大的工程要建三百年" /><published>2024-10-20T00:00:00+08:00</published><updated>2024-10-20T00:00:00+08:00</updated><id>http://localhost:4000/daguguguji/2024/10/20/the_great_project_of_300_years</id><content type="html" xml:base="http://localhost:4000/daguguguji/2024/10/20/the_great_project_of_300_years.html"><![CDATA[<p>长话短说，阿姨抱拳，六点半我正在阳台远眺，大家都知道我住3000平米大平层。</p>

<p>天气很好，通透，远处天际线飞机忙忙碌碌，金星闪烁，四环堵的一塌糊涂，两条线，一红一黄，由于 led 大灯流行，黄色列亮度很高，很白，这样看起来像是一红一白，</p>

<p>要回老家了，抱歉！阿姨颔首，接下来的职责不能履行，万分抱歉，说完阿姨土下座了，我说，怎么讲，说说，</p>

<p>回老家了，房子不让住了，阿姨说，找不到住的地方，</p>

<p>原来是这样！我说，那也没有办法，没住的地方确实只好回老家了一刚，我说，回去好好建设家乡，记得一定要买房，没自己的房，家就像浮萍一样，说散就散</p>

<p>老家有房子的呀，阿姨说，还是想呆在北京，儿子工作这下也完蛋了，孙子还想在北京上学，现在看也不行了，只好去别处看看，老家总归不能回的，先去南京看看吧，上南师大也是好的</p>

<p>想多了！我说，南师大想上就上吗，哈刚把刚，阿姨突然站起来！走到阳台上远眺，阿姨说，你看，这城市璀璨，远处是北方，多少高楼大厦，一颗一颗窗户，忽明忽暗，城市的眼睛啊，现在逐渐都闭上了，你看四环，川流不息，像动脉，我从老家来，想要添砖加瓦，现在要回去</p>

<p>回去也不错，我说，走到哪里都需要，为人民服务，，为人民币服务，呵呵，劳动永远最光荣，劳动人永远最光荣，广阔天地大有作为！我说</p>

<p>再见！阿姨抱拳，走了，桌上留下门禁，钥匙，各种卡，我走到阳台，远处灯火辉煌，社会主义进入新阶段，红色横幅不断，无数的住宅楼窗户忽明忽暗，又怎样，不是你亮就是我亮，不是东方压倒西风，就是西风压倒东方，你方唱罢我登场，能见度很好，看见国贸，三里屯盈通，四环川流不息，这时想起的歌曲是美空川の流れのように，崔健，荣光或是什么，流弹打中胸膛，最后，刹那，又在想，什么是永远，我宁愿你冷酷到底，羽泉，打开窗，地暖热的要死，右手从秋裤上方伸进去，握住几把，几把冰凉。想起微博上看见人们吵吵，人民，什么的，后来又说，同胞，什么的，突然想起来，现在什么样算是同胞，我们的同胞又是什么人，有没有同胞，昨天半夜刷微博突然看见某狗逼落马的消息，先是高兴，后来又萎了，突然想起来，阳痿十几年，都忘了吃药这件事，右手从秋裤裆部开口伸进去，永远是冰凉冰凉的一团，分不清哪是龟头哪是卵泡，冰凉一片。2008年初，长桥，电视塔下，藏书羊肉还没开店，大家都知道火车站要拆了，盖高铁站，伟大的工程要建三百年，却不知道一场大雪就要来</p>]]></content><author><name></name></author><category term="daguguguji" /><summary type="html"><![CDATA[长话短说，阿姨抱拳，六点半我正在阳台远眺，大家都知道我住3000平米大平层。]]></summary></entry><entry><title type="html">宇宙是一个假象，是不是</title><link href="http://localhost:4000/daguguguji/2024/10/20/universe_is_fake.html" rel="alternate" type="text/html" title="宇宙是一个假象，是不是" /><published>2024-10-20T00:00:00+08:00</published><updated>2024-10-20T00:00:00+08:00</updated><id>http://localhost:4000/daguguguji/2024/10/20/universe_is_fake</id><content type="html" xml:base="http://localhost:4000/daguguguji/2024/10/20/universe_is_fake.html"><![CDATA[<p>宇宙是一个假象，是不是。我不相信当代科学。除非有一个人骑马一直朝前走，路过所有的草原，海，山，爱情，相遇，别离，城市和岁月，最终回到你身边，这样我才同意你球可能是圆的，对不对。</p>]]></content><author><name></name></author><category term="daguguguji" /><summary type="html"><![CDATA[宇宙是一个假象，是不是。我不相信当代科学。除非有一个人骑马一直朝前走，路过所有的草原，海，山，爱情，相遇，别离，城市和岁月，最终回到你身边，这样我才同意你球可能是圆的，对不对。]]></summary></entry><entry><title type="html">你会无缘无故爱一个人吗</title><link href="http://localhost:4000/daguguguji/2024/10/20/with_no_reason.html" rel="alternate" type="text/html" title="你会无缘无故爱一个人吗" /><published>2024-10-20T00:00:00+08:00</published><updated>2024-10-20T00:00:00+08:00</updated><id>http://localhost:4000/daguguguji/2024/10/20/with_no_reason</id><content type="html" xml:base="http://localhost:4000/daguguguji/2024/10/20/with_no_reason.html"><![CDATA[<p>你会无缘无故，爱一个人吗</p>

<p>你会无缘无故恨一个人吗</p>

<p>你上过学吗，你在学校学到什么</p>

<p>你的生活哲学是什么</p>

<p>你会伤害别人吗</p>

<p>一个人无缘无故说爱你</p>

<p>一个人无缘无故说恨你</p>

<p>一个人，</p>

<p>很久不见，又突然出现，欲言又止，言辞激烈，给了你一拳，旋即站在旁边</p>

<p>好像突然出现一样突然</p>

<p>一个亲爱的人向你开枪</p>

<p>连续开了五枪</p>

<p>左轮手枪</p>

<p>分别是第一枪，</p>

<p>第二枪，</p>

<p>第三枪，</p>

<p>第四枪，</p>

<p>第五枪。</p>

<p>还剩一颗做保险</p>

<p>很严谨</p>

<p>请问日后写传记时哪一枪是最后一枪</p>

<p>你热爱工作岗位吗</p>

<p>你有未来规划吗</p>

<p>你日常娱乐是什么</p>

<p>爱唱卡拉OK吗</p>

<p>有没有出过国</p>

<p>去过日本吗</p>

<p>如果未来失业</p>

<p>你怎么办</p>

<p>如果猪肉吃不起了</p>

<p>你会不会感到伤心</p>]]></content><author><name></name></author><category term="daguguguji" /><summary type="html"><![CDATA[你会无缘无故，爱一个人吗]]></summary></entry><entry><title type="html">共同进步，一个都不能落下</title><link href="http://localhost:4000/daguguguji/2024/10/20/xu_kun.html" rel="alternate" type="text/html" title="共同进步，一个都不能落下" /><published>2024-10-20T00:00:00+08:00</published><updated>2024-10-20T00:00:00+08:00</updated><id>http://localhost:4000/daguguguji/2024/10/20/xu_kun</id><content type="html" xml:base="http://localhost:4000/daguguguji/2024/10/20/xu_kun.html"><![CDATA[<p>前阵子我朋友见蔡徐坤，他问徐坤，现在所有选秀的节目里面的年轻人都在呼喊口号，诸如，音乐就是我的生命，音乐就是我的另一半等等。这些口号在我眼里都是空大的，他问徐坤怎么看。</p>

<p>徐坤回答说，口号不是什么问题，但说出这些话的时候要想一想，自己到底付出过什么？在付出过之后又得到了什么？音乐对我来说是工作，是生活的一部分，所以我不会给它口号。</p>

<p>我朋友认为他提的两个问题最终指向的是，热爱不应该高尚化，即便理想主义最终考验的是热爱的成本。而这个成本花没花够之外，还要追问到底有没有一定的回报率。这个回报率有天分的因素，也有职业化的效率。经过这样的检测，似乎才有底气才能去说一些斩钉截铁的话。</p>

<p>我说坤的口号不是唱，跳，拉普，篮球吗？我朋友说，什么是拉普，我说就是说唱，现在很流行的一种文化，就一个人站在那逼逼叨逼逼叨翻来倒去说些鸡毛蒜皮的牢骚，配合一点律动，晃晃膀子扭扭胯啥的，表达没钱的苦恼，我朋友说，那叫外普，是一种黑人流行文化，国内叫喊麦，是年轻人表达态度的一种方式，我说年轻人现在表达态度不都直接开骂么，我朋友说，那是普通年轻人，有点文化的一般用外普，比如歌星啊偶像啊，你直接开骂，不体面，再说唱，跳，外普，篮球并不是坤的口号，只是他的爱好，我说坤不是自己说的吗，喜欢唱，跳，拉普，篮球，我朋友说，坤是说自己喜欢唱，跳，外普汗篮球，并不是说唱，跳，外普，篮球是他口号，他没有用唱，跳，拉普，篮球来做一种号召，或者slogan来符号化自己，这一点很不简单，徐坤他是个很有思想的人，对生活有自己的看法，我说，到底是外普，还是拉普，我朋友说，是外普，我说，原来是这样，徐坤还蛮厉害的，我朋友说，这一点很不简单啊，很多明星偶像都没有，只知道喊口号，要怎么样怎么样的，实际上自己根本做不到，甚至连自己都不知道自己的口号代表什么，很混乱，不仅把自己搞蒙了，粉丝也跟着蒙圈，我说，你是指⭐吗？⭐也很努力啊，我朋友说，没有没有，我没说⭐，绝对不是，我没有，我是泛指，泛指娱乐圈的一种现象，不是具体说谁，没有的，我就是觉得坤不简单，能独立思考，我说，确实，这样一说坤还真不简单呢，只是强调自己爱好是唱，跳，拉普，篮球，并没有把这些当口号，不是说要用这些去吸引粉丝，给粉丝洗脑，而是用自己的这些爱好来引导年轻人，引导粉丝热爱生活，健康生活，快乐生活，树立一种积极向上的，输出正能量的人生观，价值观，世界观，还真是不简单呢，我感觉徐坤不仅能独立思考，而且思考的很厉害，有完整的一套逻辑体系，首先能说服自己，这样才能去影响别人，特别好，我朋友说，是外普，我说，外普</p>

<p>这周我朋友见了一个年纪轻轻就拿过金马奖最佳编剧的他朋友。当我朋友抱怨，现在影视行业环境太差了，从红头文件，到平台资本嗜血不规则，还有行业内部的政治人事，以及追逐的意识形态，都不是一个做事的光景。影视公司死了很多家，有决策失误，有项目垫资账期回不来，有因人落马，差不多是一百种死法。</p>

<p>做内容的在这个年代，如果行业养活不了一些兢兢业业，做事正直的人，我朋友觉得是这个环境的耻辱。我朋友他朋友正在做自己的电影，她说，我做影视都怀着一种感恩，本身从事这职业我没想到名利这些事，有那么多比我天才的人，比如黑泽明到晚年还要辛辛苦苦跟好莱坞乞讨才能拍乱，都成了电影天皇也曾经试图自杀过。我还能做着自己手头上的事情，那么我没什么抱怨的。</p>

<p>我朋友觉得很多人的成功都是一种认命和发愿的修行。当一轮明月照彩云的时候，你看不到月之朔面，都是些坑坑洼洼的撞击。</p>

<p>是这样啊，我说，你这个朋友也有独立思考能力，确实特别重要，我现在很少独立思考了，一思考，浑身都疼，我可能痛风了，我朋友说，是经常吃海鲜吗，我说，不是，天天吃外卖，添加剂过多，重金属损伤大脑，我可能智障了，我朋友说，那得要注意了，少吃外卖，少上网，现在的网你可千万不要小看，马上就5g了，能量密度越来越大，对大脑损伤很厉害的，可以考虑做一个不锈钢屏蔽罩戴在头上，减少大数据冲击脑部，外卖少吃，还是要健康生活，我说，其实没什么，时代是进步的，大家都吃外卖，都看玩手机，接受的东西都是一样的，时间长了想法也就一致了，这是时代发展的趋势，大家相互理解了，心往一处想，劲往一处使，有文化的人不伤心，特别好，偶像的作用也是加速这个进程，是一种时代进步的催化剂，你看我们不仅有坤，还有⭐，还有千千万万你朋友那种对工作怀有感恩的心，感谢自己还没被时代抛弃的文艺工作者，不仅有你，也有我，你中有我，我中有你，我们中华民族是一体的，这就是命运共同体啊，特别好，以后还会更好，真是谢天谢地谢坤啊，我朋友说，我看你思考的挺溜的，不像智障了啊，我说，回光返照吧，一阵一阵的，时好时坏，反正不太灵，智障是一定了，就看哪一天，未来还是要看年轻人，希望在你们身上，忘了吧，忘了我，我都智障了，我朋友说，那可不行，共同进步，一个都不能落下</p>]]></content><author><name></name></author><category term="daguguguji" /><summary type="html"><![CDATA[前阵子我朋友见蔡徐坤，他问徐坤，现在所有选秀的节目里面的年轻人都在呼喊口号，诸如，音乐就是我的生命，音乐就是我的另一半等等。这些口号在我眼里都是空大的，他问徐坤怎么看。]]></summary></entry><entry><title type="html">Some Reality Education</title><link href="http://localhost:4000/blog/2024/10/19/reality_education.html" rel="alternate" type="text/html" title="Some Reality Education" /><published>2024-10-19T00:00:00+08:00</published><updated>2024-10-19T00:00:00+08:00</updated><id>http://localhost:4000/blog/2024/10/19/reality_education</id><content type="html" xml:base="http://localhost:4000/blog/2024/10/19/reality_education.html"><![CDATA[<p>今天参加了粉红跑 5km 活动，去时停车场没有公共车位了，我停在了在停车场里经营的一个咖啡馆门口，咖啡馆还没开门。活动结束我开车回家后接到警察电话，说我在共青森林公园停车时，把店家门口的一块瓷砖压坏了，问我是否同意把我的联系方式给店主私下沟通，我同意了。加了店主，他发来门口监控视频，是我往前开时挂到地砖边缘把一块砖带了起来，我问这个需要多少钱，他说瓷砖没坏的话人工六七百，如果要新买瓷砖的话一两千，具体问问施工师傅。我要来了现场照片，没有碎，和一点水泥砂石就可以恢复粘合，最后问我索取 850，可以看出这个人没有解决问题的诚意，只是期望利用我的无心之过敲我一笔竹杠。而我也决定给他一点社会现实的教育，因为事实是 nobody cares about a fucking brick。</p>

<blockquote>
  <p>M: 好的、我没注意到，这个多少钱啊? [2024-10-19 10:59]</p>

  <p>M: 现场照片能给我看下吗？[2024-10-19 11:00]</p>

  <p>H: 下午发给你，现在我岀去了[2024-10-19 11:17]
<img src="https://www.dropbox.com/scl/fi/qkf8ziommndzn9rpxxe34/20241019.jpg?rlkey=i9qk6kzt9qughuslklqe29trf&amp;st=bumfkl6z&amp;raw=1" alt="" />
H: 装修公司来看过了，一共850元500元人工费还有的材料费和运费[2024-10-19 19:03]</p>

  <p>M: 哥们，你看我像那么好忽悠的人吗？糊两铲子水泥的事你人工费500，没空玩你这套哈[2024-10-19 19:26]</p>
</blockquote>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[今天参加了粉红跑 5km 活动，去时停车场没有公共车位了，我停在了在停车场里经营的一个咖啡馆门口，咖啡馆还没开门。活动结束我开车回家后接到警察电话，说我在共青森林公园停车时，把店家门口的一块瓷砖压坏了，问我是否同意把我的联系方式给店主私下沟通，我同意了。加了店主，他发来门口监控视频，是我往前开时挂到地砖边缘把一块砖带了起来，我问这个需要多少钱，他说瓷砖没坏的话人工六七百，如果要新买瓷砖的话一两千，具体问问施工师傅。我要来了现场照片，没有碎，和一点水泥砂石就可以恢复粘合，最后问我索取 850，可以看出这个人没有解决问题的诚意，只是期望利用我的无心之过敲我一笔竹杠。而我也决定给他一点社会现实的教育，因为事实是 nobody cares about a fucking brick。]]></summary></entry><entry><title type="html">Large Language Models and Prompt Engineering</title><link href="http://localhost:4000/go_big/2024/10/10/llm_and_prompt_engineer.html" rel="alternate" type="text/html" title="Large Language Models and Prompt Engineering" /><published>2024-10-10T00:00:00+08:00</published><updated>2024-10-10T00:00:00+08:00</updated><id>http://localhost:4000/go_big/2024/10/10/llm_and_prompt_engineer</id><content type="html" xml:base="http://localhost:4000/go_big/2024/10/10/llm_and_prompt_engineer.html"><![CDATA[<h3 id="background">Background</h3>
<p>在传统编程中，想让计算机做出判断，需要将完整的判断标准 hard code 进脚本，在这个阶段计算机还只是一个机器。</p>

<p>在神经网络 (neural network) 浪潮里，当你向经过训练的机器学习模型输入某种信息，它基于一定的预测能力可以返回一个预测结果。</p>

<p>进入生成式语言模型 (generative language model) 时代后，使用者可以生成自己的内容，无论是文本、图片、音频、视频。我们只需要向语言模型提出问题，可以是在对话框中输入文字或者以口头交谈的形式。</p>

<h3 id="large-language-model-vs-machine-learning">Large Language Model vs Machine Learning</h3>
<p>传统机器学习开发需要有样例数据来训练模型，同时需要花费计算时间和硬件资源，针对不同的使用场景需要开发人员训练不同的模型。</p>

<p>在大语言模型中，使用者不需要成为专家，不需要收集训练数据，一个模型可以被用来解决通用的问题。你所需要做的只是考虑如何设计你的提示词，创建出清晰、简洁且信息丰富的问题。</p>

<h3 id="what-is-large-language-model">What is Large Language Model</h3>
<p>大语言模型是机器学习中深度学习 (Deep Learning) 的一个子集，它是一个可以预先训练、根据特定的目标进行微调的大型通用语言模型，可以被用来处理如文本分类、问答、文档摘要、文本生成等问题。现阶段大语言模型一个常见的应用是生成式人工智能 (Generative AI)。</p>

<p>与机器学习模型相比，LLM 具有以下几个特点：</p>

<h4 id="large">Large</h4>
<ul>
  <li>训练数据集 (training dataset) 的规模大，通常可以达到 PB 级；</li>
  <li>参数 (parameter) 的数量大，参数通常指的是机器从模型训练中学到的记忆和知识。</li>
</ul>

<h4 id="general-purpose">General purpose</h4>
<p>基于人类语言的共通性，LLM 可以用来解决人类通用的问题。</p>

<h4 id="pre-trained-and-fine-tuned">Pre-trained and fine-tuned</h4>
<p>使用大量数据集在大型语言模型中预先进行训练，然后使用较小的数据集对其进行微调用以实现特定的目标。</p>

<h3 id="popular-tools">Popular Tools</h3>
<p>现在市面上常用的生成式人工智能对话工具有: <a href="https://www.openai.com/chatgpt">OpenAI ChatGPT</a>, <a href="https://bard.google.com">Google Bard</a>, <a href="https://www.microsoft.com/en-us/microsoft-365/copilot">Microsoft Copilot</a>, <a href="https://www.anthropic.com/">Anthropic Claude</a>, <a href="https://ai.facebook.com/">Meta LLaMA</a>;</p>

<p>以及集成各种语言模型到特定应用场景的工具: <a href="https://www.cursor.com/">Cursor</a>, <a href="https://www.perplexity.ai/">Perplexity AI</a>;</p>

<p>以及生成图片、视频的工具: <a href="https://openai.com/dall-e">OpenAI DALL-E</a>, <a href="https://www.midjourney.com">Midjourney</a>, <a href="https://stability.ai/stable-diffusion">Stable Diffusion</a>, <a href="https://runwayml.com">Runway ML</a>, <a href="https://www.synthesia.io">Synthesia</a>。</p>

<h3 id="how-to-prompt">How to Prompt</h3>
<p>下面介绍一种比较高效的 LLM 提问框架: <strong>CO-STAR</strong>。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- C - Context（上下文）: 提供足够的背景信息，以帮助模型理解问题的背景和目的；
- O - Objective（目标）: 明确你希望模型实现的目标或任务，例如回答问题、提供建议或生成文本；
- S - Style（风格）: 指定你希望模型使用的语言风格或语气，比如正式、非正式、幽默等；
- T - Tone（语调）: 设定模型的语调，例如友好、专业、鼓励等，以便更好地与用户的需求匹配；
- A - Audience（受众）: 明确目标受众，帮助模型调整内容以适应特定的读者群体；
- R - Response（响应）: 指定期望的响应格式或结构，例如简短回答、详细解释或列表形式。
</code></pre></div></div>

<p>在我的另一篇博客中我列举了我使用 Cursor 时预设的规则以达到期望的效果：<a href="https://thekingof.cool/blog/2024/09/17/rules_of_ai.html">Rules of AI in Cursor</a>。</p>

<h3 id="experience-and-beyond">Experience and Beyond</h3>
<p>就像人类学习说话一样，优秀的提示词工程师需要根据自身需求不断地去与模型交互，并形成一套自己的高效对话方式。</p>

<p>人工智能接管人类或许是迟早的事，但在这之前，充分利用它或多或少能让我们更适应这个变化着的世界，以及，用马斯克的话说，to understand the universe。</p>

<blockquote>
  <p><a href="https://x.ai/">xAI</a> is a company working on <strong>building artificial intelligence to accelerate human scientific discovery</strong>. We are guided by our mission to <strong>advance our collective understanding of the universe</strong>.</p>
</blockquote>]]></content><author><name></name></author><category term="go_big" /><summary type="html"><![CDATA[Background 在传统编程中，想让计算机做出判断，需要将完整的判断标准 hard code 进脚本，在这个阶段计算机还只是一个机器。]]></summary></entry><entry><title type="html">What is Machine Learning</title><link href="http://localhost:4000/go_big/2024/10/08/machine_learning.html" rel="alternate" type="text/html" title="What is Machine Learning" /><published>2024-10-08T00:00:00+08:00</published><updated>2024-10-08T00:00:00+08:00</updated><id>http://localhost:4000/go_big/2024/10/08/machine_learning</id><content type="html" xml:base="http://localhost:4000/go_big/2024/10/08/machine_learning.html"><![CDATA[<h3 id="what-is-machine-learning">What is Machine Learning</h3>
<p>机器学习是一种让计算机模拟人脑从数据中学习并做出决策的过程，而不是过去那样利用计算机通过明确的编程指令完成特定任务。</p>

<p>也有说法是，</p>

<blockquote>
  <p>碳基生物是硅基生物的启动程序。</p>
</blockquote>

<p>谁知道呢？</p>

<p>机器学习由数据和模型构成。机器学习的实现依赖数据，这个数据可以是一切形式的信息；模型是机器学习的核心，它是一个数学结构，用于基于数据做出预测。</p>

<p>根据提供的数据类型和模型机制，机器学习分为 <strong>监督学习</strong>、<strong>无监督学习</strong> 和 <strong>强化学习</strong>。</p>

<ol>
  <li>
    <p>监督学习 (Supervised Learning) 中，给定一组目标对象的特征数据，及其对应的标签，让计算机模型学习进行预测。代表性的算法有线性回归 (Linear Regression)、逻辑回归 (Logistic Regression)、决策树 (Decision Tree) 等。</p>
  </li>
  <li>
    <p>无监督学习 (Unsupervised Learning) 中，只给计算机提供输入数据，让模型尝试找到数据中的模式和分类。代表性的算法包括聚类 (Clustering)、主成分分析 (Principal Component Analysis)。</p>
  </li>
  <li>
    <p>强化学习 (Reinforcement Learning) 类似于训练宠物，通过给试错后的模型以奖励或者惩罚，来达到想要的效果。代表性算法有 Q-learning、深度 Q 网络 (Deep Q-Network)。</p>
  </li>
</ol>

<h3 id="machine-learning-library">Machine Learning Library</h3>
<p>为了帮助开发者更容易构建、训练和评估机器学习模型，一些机器学习库被开发出来。这些机器学习库由一些预先编写的代码和工具构成，它们提供了许多常用的算法、数据处理工具，使机器学习的实现更加高效和便捷。</p>

<p>常用的机器学习库包括 <strong><a href="https://scikit-learn.org/stable/">Scikit-learn</a></strong>, <strong><a href="https://www.tensorflow.org/">TensorFlow</a></strong>, <strong><a href="https://pytorch.org/">PyTorch</a></strong>。</p>

<h3 id="how-to-machine-learning">How to Machine Learning</h3>
<p>下面以 Scikit-learn 为例，简单跑一遍机器学习的流程。</p>

<h4 id="install-necessary-packages">Install Necessary Packages</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>scikit-learn pandas
</code></pre></div></div>

<h4 id="hello-world">Hello World</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 导入必须的包
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># 加载数据集（Scikit-learn 自带的鸢尾花数据集）
</span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="nf">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span>  <span class="c1"># 特征
</span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>  <span class="c1"># 标签
</span>
<span class="c1"># X = array([[5.1, 3.5, 1.4, 0.2],
#        [4.9, 3. , 1.4, 0.2],
#        [4.7, 3.2, 1.3, 0.2],
#        [4.6, 3.1, 1.5, 0.2],
#        [5. , 3.6, 1.4, 0.2],
#        [5.4, 3.9, 1.7, 0.4],
#        [4.6, 3.4, 1.4, 0.3],
#        [5. , 3.4, 1.5, 0.2],
#        [4.4, 2.9, 1.4, 0.2],
#        [4.9, 3.1, 1.5, 0.1],
#        [5.4, 3.7, 1.5, 0.2],
#        [4.8, 3.4, 1.6, 0.2],
#        [4.8, 3. , 1.4, 0.1],
#        [4.3, 3. , 1.1, 0.1],
#        [5.8, 4. , 1.2, 0.2],
#        [5.7, 4.4, 1.5, 0.4],
#        [5.4, 3.9, 1.3, 0.4],
#        [5.1, 3.5, 1.4, 0.3],
#        [5.7, 3.8, 1.7, 0.3],
#        [5.1, 3.8, 1.5, 0.3],
#        [5.4, 3.4, 1.7, 0.2],
#        [5.1, 3.7, 1.5, 0.4],
#        [4.6, 3.6, 1. , 0.2],
#        [5.1, 3.3, 1.7, 0.5],
#        [4.8, 3.4, 1.9, 0.2],
#        [5. , 3. , 1.6, 0.2],
#        [5. , 3.4, 1.6, 0.4],
#        [5.2, 3.5, 1.5, 0.2],
#        [5.2, 3.4, 1.4, 0.2],
#        [4.7, 3.2, 1.6, 0.2],
#        [4.8, 3.1, 1.6, 0.2],
#        [5.4, 3.4, 1.5, 0.4],
#        [5.2, 4.1, 1.5, 0.1],
#        [5.5, 4.2, 1.4, 0.2],
#        [4.9, 3.1, 1.5, 0.2],
#        [5. , 3.2, 1.2, 0.2],
#        [5.5, 3.5, 1.3, 0.2],
#        [4.9, 3.6, 1.4, 0.1],
#        [4.4, 3. , 1.3, 0.2],
#        [5.1, 3.4, 1.5, 0.2],
#        [5. , 3.5, 1.3, 0.3],
#        [4.5, 2.3, 1.3, 0.3],
#        [4.4, 3.2, 1.3, 0.2],
#        [5. , 3.5, 1.6, 0.6],
#        [5.1, 3.8, 1.9, 0.4],
#        [4.8, 3. , 1.4, 0.3],
#        [5.1, 3.8, 1.6, 0.2],
#        [4.6, 3.2, 1.4, 0.2],
#        [5.3, 3.7, 1.5, 0.2],
#        [5. , 3.3, 1.4, 0.2],
#        [7. , 3.2, 4.7, 1.4],
#        [6.4, 3.2, 4.5, 1.5],
#        [6.9, 3.1, 4.9, 1.5],
#        [5.5, 2.3, 4. , 1.3],
#        [6.5, 2.8, 4.6, 1.5],
#        [5.7, 2.8, 4.5, 1.3],
#        [6.3, 3.3, 4.7, 1.6],
#        [4.9, 2.4, 3.3, 1. ],
#        [6.6, 2.9, 4.6, 1.3],
#        [5.2, 2.7, 3.9, 1.4],
#        [5. , 2. , 3.5, 1. ],
#        [5.9, 3. , 4.2, 1.5],
#        [6. , 2.2, 4. , 1. ],
#        [6.1, 2.9, 4.7, 1.4],
#        [5.6, 2.9, 3.6, 1.3],
#        [6.7, 3.1, 4.4, 1.4],
#        [5.6, 3. , 4.5, 1.5],
#        [5.8, 2.7, 4.1, 1. ],
#        [6.2, 2.2, 4.5, 1.5],
#        [5.6, 2.5, 3.9, 1.1],
#        [5.9, 3.2, 4.8, 1.8],
#        [6.1, 2.8, 4. , 1.3],
#        [6.3, 2.5, 4.9, 1.5],
#        [6.1, 2.8, 4.7, 1.2],
#        [6.4, 2.9, 4.3, 1.3],
#        [6.6, 3. , 4.4, 1.4],
#        [6.8, 2.8, 4.8, 1.4],
#        [6.7, 3. , 5. , 1.7],
#        [6. , 2.9, 4.5, 1.5],
#        [5.7, 2.6, 3.5, 1. ],
#        [5.5, 2.4, 3.8, 1.1],
#        [5.5, 2.4, 3.7, 1. ],
#        [5.8, 2.7, 3.9, 1.2],
#        [6. , 2.7, 5.1, 1.6],
#        [5.4, 3. , 4.5, 1.5],
#        [6. , 3.4, 4.5, 1.6],
#        [6.7, 3.1, 4.7, 1.5],
#        [6.3, 2.3, 4.4, 1.3],
#        [5.6, 3. , 4.1, 1.3],
#        [5.5, 2.5, 4. , 1.3],
#        [5.5, 2.6, 4.4, 1.2],
#        [6.1, 3. , 4.6, 1.4],
#        [5.8, 2.6, 4. , 1.2],
#        [5. , 2.3, 3.3, 1. ],
#        [5.6, 2.7, 4.2, 1.3],
#        [5.7, 3. , 4.2, 1.2],
#        [5.7, 2.9, 4.2, 1.3],
#        [6.2, 2.9, 4.3, 1.3],
#        [5.1, 2.5, 3. , 1.1],
#        [5.7, 2.8, 4.1, 1.3],
#        [6.3, 3.3, 6. , 2.5],
#        [5.8, 2.7, 5.1, 1.9],
#        [7.1, 3. , 5.9, 2.1],
#        [6.3, 2.9, 5.6, 1.8],
#        [6.5, 3. , 5.8, 2.2],
#        [7.6, 3. , 6.6, 2.1],
#        [4.9, 2.5, 4.5, 1.7],
#        [7.3, 2.9, 6.3, 1.8],
#        [6.7, 2.5, 5.8, 1.8],
#        [7.2, 3.6, 6.1, 2.5],
#        [6.5, 3.2, 5.1, 2. ],
#        [6.4, 2.7, 5.3, 1.9],
#        [6.8, 3. , 5.5, 2.1],
#        [5.7, 2.5, 5. , 2. ],
#        [5.8, 2.8, 5.1, 2.4],
#        [6.4, 3.2, 5.3, 2.3],
#        [6.5, 3. , 5.5, 1.8],
#        [7.7, 3.8, 6.7, 2.2],
#        [7.7, 2.6, 6.9, 2.3],
#        [6. , 2.2, 5. , 1.5],
#        [6.9, 3.2, 5.7, 2.3],
#        [5.6, 2.8, 4.9, 2. ],
#        [7.7, 2.8, 6.7, 2. ],
#        [6.3, 2.7, 4.9, 1.8],
#        [6.7, 3.3, 5.7, 2.1],
#        [7.2, 3.2, 6. , 1.8],
#        [6.2, 2.8, 4.8, 1.8],
#        [6.1, 3. , 4.9, 1.8],
#        [6.4, 2.8, 5.6, 2.1],
#        [7.2, 3. , 5.8, 1.6],
#        [7.4, 2.8, 6.1, 1.9],
#        [7.9, 3.8, 6.4, 2. ],
#        [6.4, 2.8, 5.6, 2.2],
#        [6.3, 2.8, 5.1, 1.5],
#        [6.1, 2.6, 5.6, 1.4],
#        [7.7, 3. , 6.1, 2.3],
#        [6.3, 3.4, 5.6, 2.4],
#        [6.4, 3.1, 5.5, 1.8],
#        [6. , 3. , 4.8, 1.8],
#        [6.9, 3.1, 5.4, 2.1],
#        [6.7, 3.1, 5.6, 2.4],
#        [6.9, 3.1, 5.1, 2.3],
#        [5.8, 2.7, 5.1, 1.9],
#        [6.8, 3.2, 5.9, 2.3],
#        [6.7, 3.3, 5.7, 2.5],
#        [6.7, 3. , 5.2, 2.3],
#        [6.3, 2.5, 5. , 1.9],
#        [6.5, 3. , 5.2, 2. ],
#        [6.2, 3.4, 5.4, 2.3],
#        [5.9, 3. , 5.1, 1.8]])
</span>
<span class="c1"># y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
</span>
<span class="c1"># 将数据集划分为训练集（20%）和测试集
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 标准化特征
</span><span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 使用 K-Nearest Neighbors 算法进行分类，创建 KNN 模型
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># 训练模型
</span><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 进行预测
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 计算准确率
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">模型准确率: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># 模型准确率: 1.00
</span>
<span class="c1"># 打印分类报告
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">分类报告:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># 分类报告:
#               precision    recall  f1-score   support
</span>
<span class="c1">#            0       1.00      1.00      1.00        10
#            1       1.00      1.00      1.00         9
#            2       1.00      1.00      1.00        11
</span>
<span class="c1">#     accuracy                           1.00        30
#    macro avg       1.00      1.00      1.00        30
# weighted avg       1.00      1.00      1.00        30
</span>
<span class="c1"># 打印混淆矩阵
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">混淆矩阵:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="c1"># [[10  0  0]
#  [ 0  9  0]
#  [ 0  0 11]]
</span></code></pre></div></div>

<h3 id="useful-links">Useful Links</h3>
<p>想要深入实践掌握 Machine Learning，除了以上提到的一些官网，还可以尝试从 <a href="https://www.kaggle.com/">Kaggle</a> 找到数据集并构建自己感兴趣的项目，在机器学习社群 (<a href="https://stackoverflow.com/">Stack Overflow</a>、<a href="https://www.kaggle.com/discussions?sort=undefined">Kaggle Discussions</a>、<a href="https://www.reddit.com/">Reddit</a>) 参与其他学习者的交流，跟踪技术的发展。</p>

<p>需要的技能：线性代数、概率论和统计学，数据处理 (NumPy &amp; Pandas) 和可视化 (Matplotlib &amp; Seaborn)。</p>

<p>多动手，多观察，多总结。</p>

<p>To Be Continued…</p>

<hr />

<p>BTW The Royal Swedish Academy of Sciences announced on October 8:
<a href="https://www.nobelprize.org/prizes/physics/2024/summary/">The Nobel Prize in Physics 2024</a> was awarded to <a href="https://en.wikipedia.org/wiki/John_Hopfield">John J. Hopfield</a> and <a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton">Geoffrey E. Hinton</a> “for foundational discoveries and inventions that enable machine learning with artificial neural networks”.</p>]]></content><author><name></name></author><category term="go_big" /><summary type="html"><![CDATA[What is Machine Learning 机器学习是一种让计算机模拟人脑从数据中学习并做出决策的过程，而不是过去那样利用计算机通过明确的编程指令完成特定任务。]]></summary></entry></feed>