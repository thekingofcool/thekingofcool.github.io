<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-10-12T12:47:22+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">thekingofcool</title><entry><title type="html">Large Language Models and Prompt Engineering</title><link href="http://localhost:4000/go_big/2024/10/10/llm_and_prompt_engineer.html" rel="alternate" type="text/html" title="Large Language Models and Prompt Engineering" /><published>2024-10-10T00:00:00+08:00</published><updated>2024-10-10T00:00:00+08:00</updated><id>http://localhost:4000/go_big/2024/10/10/llm_and_prompt_engineer</id><content type="html" xml:base="http://localhost:4000/go_big/2024/10/10/llm_and_prompt_engineer.html"><![CDATA[<h3 id="background">Background</h3>
<p>在传统编程中，想让计算机做出判断，需要将完整的判断标准 hard code 进脚本，在这个阶段计算机还只是一个机器。</p>

<p>在神经网络 (neural network) 浪潮里，当你向经过训练的机器学习模型输入某种信息，它基于一定的预测能力可以返回一个预测结果。</p>

<p>进入生成式语言模型 (generative language model) 时代后，使用者可以生成自己的内容，无论是文本、图片、音频、视频。我们只需要向语言模型提出问题，可以是在对话框中输入文字或者以口头交谈的形式。</p>

<h3 id="large-language-model-vs-machine-learning">Large Language Model vs Machine Learning</h3>
<p>传统机器学习开发需要有样例数据来训练模型，同时需要花费计算时间和硬件资源，针对不同的使用场景需要开发人员训练不同的模型。</p>

<p>在大语言模型中，使用者不需要成为专家，不需要收集训练数据，一个模型可以被用来解决通用的问题。你所需要做的只是考虑如何设计你的提示词，创建出清晰、简洁且信息丰富的问题。</p>

<h3 id="what-is-large-language-model">What is Large Language Model</h3>
<p>大语言模型是机器学习中深度学习 (Deep Learning) 的一个子集，它是一个可以预先训练、根据特定的目标进行微调的大型通用语言模型，可以被用来处理如文本分类、问答、文档摘要、文本生成等问题。现阶段大语言模型一个常见的应用是生成式人工智能 (Generative AI)。</p>

<p>与机器学习模型相比，LLM 具有以下几个特点：</p>

<h4 id="large">Large</h4>
<ul>
  <li>训练数据集 (training dataset) 的规模大，通常可以达到 PB 级；</li>
  <li>参数 (parameter) 的数量大，参数通常指的是机器从模型训练中学到的记忆和知识。</li>
</ul>

<h4 id="general-purpose">General purpose</h4>
<p>基于人类语言的共通性，LLM 可以用来解决人类通用的问题。</p>

<h4 id="pre-trained-and-fine-tuned">Pre-trained and fine-tuned</h4>
<p>使用大量数据集在大型语言模型中预先进行训练，然后使用较小的数据集对其进行微调用以实现特定的目标。</p>

<h3 id="popular-tools">Popular Tools</h3>
<p>现在市面上常用的生成式人工智能对话工具有: <a href="https://www.openai.com/chatgpt">OpenAI ChatGPT</a>, <a href="https://bard.google.com">Google Bard</a>, <a href="https://www.microsoft.com/en-us/microsoft-365/copilot">Microsoft Copilot</a>, <a href="https://www.anthropic.com/">Anthropic Claude</a>, <a href="https://ai.facebook.com/">Meta LLaMA</a>;</p>

<p>以及集成各种语言模型到特定应用场景的工具: <a href="https://www.cursor.com/">Cursor</a>, <a href="https://www.perplexity.ai/">Perplexity AI</a>;</p>

<p>以及生成图片、视频的工具: <a href="https://openai.com/dall-e">OpenAI DALL-E</a>, <a href="https://www.midjourney.com">Midjourney</a>, <a href="https://stability.ai/stable-diffusion">Stable Diffusion</a>, <a href="https://runwayml.com">Runway ML</a>, <a href="https://www.synthesia.io">Synthesia</a>。</p>

<h3 id="how-to-prompt">How to Prompt</h3>
<p>下面介绍一种比较高效的 LLM 提问框架: <strong>CO-STAR</strong>。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- C - Context（上下文）: 提供足够的背景信息，以帮助模型理解问题的背景和目的；
- O - Objective（目标）: 明确你希望模型实现的目标或任务，例如回答问题、提供建议或生成文本；
- S - Style（风格）: 指定你希望模型使用的语言风格或语气，比如正式、非正式、幽默等；
- T - Tone（语调）: 设定模型的语调，例如友好、专业、鼓励等，以便更好地与用户的需求匹配；
- A - Audience（受众）: 明确目标受众，帮助模型调整内容以适应特定的读者群体；
- R - Response（响应）: 指定期望的响应格式或结构，例如简短回答、详细解释或列表形式。
</code></pre></div></div>

<p>在我的另一篇博客中我列举了我使用 Cursor 时预设的规则以达到期望的效果：<a href="https://thekingof.cool/blog/2024/09/17/rules_of_ai.html">Rules of AI in Cursor</a>。</p>

<h3 id="experience-and-beyond">Experience and Beyond</h3>
<p>就像人类学习说话一样，优秀的提示词工程师需要根据自身需求不断地去与模型交互，并形成一套自己的高效对话方式。</p>

<p>人工智能接管人类或许是迟早的事，但在这之前，充分利用它或多或少能让我们更适应这个变化着的世界，以及，用马斯克的话说，to understand the universe。</p>

<blockquote>
  <p><a href="https://x.ai/">xAI</a> is a company working on <strong>building artificial intelligence to accelerate human scientific discovery</strong>. We are guided by our mission to <strong>advance our collective understanding of the universe</strong>.</p>
</blockquote>]]></content><author><name></name></author><category term="go_big" /><summary type="html"><![CDATA[Background 在传统编程中，想让计算机做出判断，需要将完整的判断标准 hard code 进脚本，在这个阶段计算机还只是一个机器。]]></summary></entry><entry><title type="html">What is Machine Learning</title><link href="http://localhost:4000/go_big/2024/10/08/machine_learning.html" rel="alternate" type="text/html" title="What is Machine Learning" /><published>2024-10-08T00:00:00+08:00</published><updated>2024-10-08T00:00:00+08:00</updated><id>http://localhost:4000/go_big/2024/10/08/machine_learning</id><content type="html" xml:base="http://localhost:4000/go_big/2024/10/08/machine_learning.html"><![CDATA[<h3 id="what-is-machine-learning">What is Machine Learning</h3>
<p>机器学习是一种让计算机模拟人脑从数据中学习并做出决策的过程，而不是过去那样利用计算机通过明确的编程指令完成特定任务。</p>

<p>也有说法是，</p>

<blockquote>
  <p>碳基生物是硅基生物的启动程序。</p>
</blockquote>

<p>谁知道呢？</p>

<p>机器学习由数据和模型构成。机器学习的实现依赖数据，这个数据可以是一切形式的信息；模型是机器学习的核心，它是一个数学结构，用于基于数据做出预测。</p>

<p>根据提供的数据类型和模型机制，机器学习分为 <strong>监督学习</strong>、<strong>无监督学习</strong> 和 <strong>强化学习</strong>。</p>

<ol>
  <li>
    <p>监督学习 (Supervised Learning) 中，给定一组目标对象的特征数据，及其对应的标签，让计算机模型学习进行预测。代表性的算法有线性回归 (Linear Regression)、逻辑回归 (Logistic Regression)、决策树 (Decision Tree) 等。</p>
  </li>
  <li>
    <p>无监督学习 (Unsupervised Learning) 中，只给计算机提供输入数据，让模型尝试找到数据中的模式和分类。代表性的算法包括聚类 (Clustering)、主成分分析 (Principal Component Analysis)。</p>
  </li>
  <li>
    <p>强化学习 (Reinforcement Learning) 类似于训练宠物，通过给试错后的模型以奖励或者惩罚，来达到想要的效果。代表性算法有 Q-learning、深度 Q 网络 (Deep Q-Network)。</p>
  </li>
</ol>

<h3 id="machine-learning-library">Machine Learning Library</h3>
<p>为了帮助开发者更容易构建、训练和评估机器学习模型，一些机器学习库被开发出来。这些机器学习库由一些预先编写的代码和工具构成，它们提供了许多常用的算法、数据处理工具，使机器学习的实现更加高效和便捷。</p>

<p>常用的机器学习库包括 <strong><a href="https://scikit-learn.org/stable/">Scikit-learn</a></strong>, <strong><a href="https://www.tensorflow.org/">TensorFlow</a></strong>, <strong><a href="https://pytorch.org/">PyTorch</a></strong>。</p>

<h3 id="how-to-machine-learning">How to Machine Learning</h3>
<p>下面以 Scikit-learn 为例，简单跑一遍机器学习的流程。</p>

<h4 id="install-necessary-packages">Install Necessary Packages</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>scikit-learn pandas
</code></pre></div></div>

<h4 id="hello-world">Hello World</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 导入必须的包
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># 加载数据集（Scikit-learn 自带的鸢尾花数据集）
</span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="nf">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span>  <span class="c1"># 特征
</span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>  <span class="c1"># 标签
</span>
<span class="c1"># X = array([[5.1, 3.5, 1.4, 0.2],
#        [4.9, 3. , 1.4, 0.2],
#        [4.7, 3.2, 1.3, 0.2],
#        [4.6, 3.1, 1.5, 0.2],
#        [5. , 3.6, 1.4, 0.2],
#        [5.4, 3.9, 1.7, 0.4],
#        [4.6, 3.4, 1.4, 0.3],
#        [5. , 3.4, 1.5, 0.2],
#        [4.4, 2.9, 1.4, 0.2],
#        [4.9, 3.1, 1.5, 0.1],
#        [5.4, 3.7, 1.5, 0.2],
#        [4.8, 3.4, 1.6, 0.2],
#        [4.8, 3. , 1.4, 0.1],
#        [4.3, 3. , 1.1, 0.1],
#        [5.8, 4. , 1.2, 0.2],
#        [5.7, 4.4, 1.5, 0.4],
#        [5.4, 3.9, 1.3, 0.4],
#        [5.1, 3.5, 1.4, 0.3],
#        [5.7, 3.8, 1.7, 0.3],
#        [5.1, 3.8, 1.5, 0.3],
#        [5.4, 3.4, 1.7, 0.2],
#        [5.1, 3.7, 1.5, 0.4],
#        [4.6, 3.6, 1. , 0.2],
#        [5.1, 3.3, 1.7, 0.5],
#        [4.8, 3.4, 1.9, 0.2],
#        [5. , 3. , 1.6, 0.2],
#        [5. , 3.4, 1.6, 0.4],
#        [5.2, 3.5, 1.5, 0.2],
#        [5.2, 3.4, 1.4, 0.2],
#        [4.7, 3.2, 1.6, 0.2],
#        [4.8, 3.1, 1.6, 0.2],
#        [5.4, 3.4, 1.5, 0.4],
#        [5.2, 4.1, 1.5, 0.1],
#        [5.5, 4.2, 1.4, 0.2],
#        [4.9, 3.1, 1.5, 0.2],
#        [5. , 3.2, 1.2, 0.2],
#        [5.5, 3.5, 1.3, 0.2],
#        [4.9, 3.6, 1.4, 0.1],
#        [4.4, 3. , 1.3, 0.2],
#        [5.1, 3.4, 1.5, 0.2],
#        [5. , 3.5, 1.3, 0.3],
#        [4.5, 2.3, 1.3, 0.3],
#        [4.4, 3.2, 1.3, 0.2],
#        [5. , 3.5, 1.6, 0.6],
#        [5.1, 3.8, 1.9, 0.4],
#        [4.8, 3. , 1.4, 0.3],
#        [5.1, 3.8, 1.6, 0.2],
#        [4.6, 3.2, 1.4, 0.2],
#        [5.3, 3.7, 1.5, 0.2],
#        [5. , 3.3, 1.4, 0.2],
#        [7. , 3.2, 4.7, 1.4],
#        [6.4, 3.2, 4.5, 1.5],
#        [6.9, 3.1, 4.9, 1.5],
#        [5.5, 2.3, 4. , 1.3],
#        [6.5, 2.8, 4.6, 1.5],
#        [5.7, 2.8, 4.5, 1.3],
#        [6.3, 3.3, 4.7, 1.6],
#        [4.9, 2.4, 3.3, 1. ],
#        [6.6, 2.9, 4.6, 1.3],
#        [5.2, 2.7, 3.9, 1.4],
#        [5. , 2. , 3.5, 1. ],
#        [5.9, 3. , 4.2, 1.5],
#        [6. , 2.2, 4. , 1. ],
#        [6.1, 2.9, 4.7, 1.4],
#        [5.6, 2.9, 3.6, 1.3],
#        [6.7, 3.1, 4.4, 1.4],
#        [5.6, 3. , 4.5, 1.5],
#        [5.8, 2.7, 4.1, 1. ],
#        [6.2, 2.2, 4.5, 1.5],
#        [5.6, 2.5, 3.9, 1.1],
#        [5.9, 3.2, 4.8, 1.8],
#        [6.1, 2.8, 4. , 1.3],
#        [6.3, 2.5, 4.9, 1.5],
#        [6.1, 2.8, 4.7, 1.2],
#        [6.4, 2.9, 4.3, 1.3],
#        [6.6, 3. , 4.4, 1.4],
#        [6.8, 2.8, 4.8, 1.4],
#        [6.7, 3. , 5. , 1.7],
#        [6. , 2.9, 4.5, 1.5],
#        [5.7, 2.6, 3.5, 1. ],
#        [5.5, 2.4, 3.8, 1.1],
#        [5.5, 2.4, 3.7, 1. ],
#        [5.8, 2.7, 3.9, 1.2],
#        [6. , 2.7, 5.1, 1.6],
#        [5.4, 3. , 4.5, 1.5],
#        [6. , 3.4, 4.5, 1.6],
#        [6.7, 3.1, 4.7, 1.5],
#        [6.3, 2.3, 4.4, 1.3],
#        [5.6, 3. , 4.1, 1.3],
#        [5.5, 2.5, 4. , 1.3],
#        [5.5, 2.6, 4.4, 1.2],
#        [6.1, 3. , 4.6, 1.4],
#        [5.8, 2.6, 4. , 1.2],
#        [5. , 2.3, 3.3, 1. ],
#        [5.6, 2.7, 4.2, 1.3],
#        [5.7, 3. , 4.2, 1.2],
#        [5.7, 2.9, 4.2, 1.3],
#        [6.2, 2.9, 4.3, 1.3],
#        [5.1, 2.5, 3. , 1.1],
#        [5.7, 2.8, 4.1, 1.3],
#        [6.3, 3.3, 6. , 2.5],
#        [5.8, 2.7, 5.1, 1.9],
#        [7.1, 3. , 5.9, 2.1],
#        [6.3, 2.9, 5.6, 1.8],
#        [6.5, 3. , 5.8, 2.2],
#        [7.6, 3. , 6.6, 2.1],
#        [4.9, 2.5, 4.5, 1.7],
#        [7.3, 2.9, 6.3, 1.8],
#        [6.7, 2.5, 5.8, 1.8],
#        [7.2, 3.6, 6.1, 2.5],
#        [6.5, 3.2, 5.1, 2. ],
#        [6.4, 2.7, 5.3, 1.9],
#        [6.8, 3. , 5.5, 2.1],
#        [5.7, 2.5, 5. , 2. ],
#        [5.8, 2.8, 5.1, 2.4],
#        [6.4, 3.2, 5.3, 2.3],
#        [6.5, 3. , 5.5, 1.8],
#        [7.7, 3.8, 6.7, 2.2],
#        [7.7, 2.6, 6.9, 2.3],
#        [6. , 2.2, 5. , 1.5],
#        [6.9, 3.2, 5.7, 2.3],
#        [5.6, 2.8, 4.9, 2. ],
#        [7.7, 2.8, 6.7, 2. ],
#        [6.3, 2.7, 4.9, 1.8],
#        [6.7, 3.3, 5.7, 2.1],
#        [7.2, 3.2, 6. , 1.8],
#        [6.2, 2.8, 4.8, 1.8],
#        [6.1, 3. , 4.9, 1.8],
#        [6.4, 2.8, 5.6, 2.1],
#        [7.2, 3. , 5.8, 1.6],
#        [7.4, 2.8, 6.1, 1.9],
#        [7.9, 3.8, 6.4, 2. ],
#        [6.4, 2.8, 5.6, 2.2],
#        [6.3, 2.8, 5.1, 1.5],
#        [6.1, 2.6, 5.6, 1.4],
#        [7.7, 3. , 6.1, 2.3],
#        [6.3, 3.4, 5.6, 2.4],
#        [6.4, 3.1, 5.5, 1.8],
#        [6. , 3. , 4.8, 1.8],
#        [6.9, 3.1, 5.4, 2.1],
#        [6.7, 3.1, 5.6, 2.4],
#        [6.9, 3.1, 5.1, 2.3],
#        [5.8, 2.7, 5.1, 1.9],
#        [6.8, 3.2, 5.9, 2.3],
#        [6.7, 3.3, 5.7, 2.5],
#        [6.7, 3. , 5.2, 2.3],
#        [6.3, 2.5, 5. , 1.9],
#        [6.5, 3. , 5.2, 2. ],
#        [6.2, 3.4, 5.4, 2.3],
#        [5.9, 3. , 5.1, 1.8]])
</span>
<span class="c1"># y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
</span>
<span class="c1"># 将数据集划分为训练集（20%）和测试集
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 标准化特征
</span><span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 使用 K-Nearest Neighbors 算法进行分类，创建 KNN 模型
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># 训练模型
</span><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 进行预测
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 计算准确率
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">模型准确率: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># 模型准确率: 1.00
</span>
<span class="c1"># 打印分类报告
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">分类报告:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># 分类报告:
#               precision    recall  f1-score   support
</span>
<span class="c1">#            0       1.00      1.00      1.00        10
#            1       1.00      1.00      1.00         9
#            2       1.00      1.00      1.00        11
</span>
<span class="c1">#     accuracy                           1.00        30
#    macro avg       1.00      1.00      1.00        30
# weighted avg       1.00      1.00      1.00        30
</span>
<span class="c1"># 打印混淆矩阵
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">混淆矩阵:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="c1"># [[10  0  0]
#  [ 0  9  0]
#  [ 0  0 11]]
</span></code></pre></div></div>

<h3 id="useful-links">Useful Links</h3>
<p>想要深入实践掌握 Machine Learning，除了以上提到的一些官网，还可以尝试从 <a href="https://www.kaggle.com/">Kaggle</a> 找到数据集并构建自己感兴趣的项目，在机器学习社群 (<a href="https://stackoverflow.com/">Stack Overflow</a>、<a href="https://www.kaggle.com/discussions?sort=undefined">Kaggle Discussions</a>、<a href="https://www.reddit.com/">Reddit</a>) 参与其他学习者的交流，跟踪技术的发展。</p>

<p>需要的技能：线性代数、概率论和统计学，数据处理 (NumPy &amp; Pandas) 和可视化 (Matplotlib &amp; Seaborn)。</p>

<p>多动手，多观察，多总结。</p>

<p>To Be Continued…</p>

<hr />

<p>BTW The Royal Swedish Academy of Sciences announced on October 8:
<a href="https://www.nobelprize.org/prizes/physics/2024/summary/">The Nobel Prize in Physics 2024</a> was awarded to <a href="https://en.wikipedia.org/wiki/John_Hopfield">John J. Hopfield</a> and <a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton">Geoffrey E. Hinton</a> “for foundational discoveries and inventions that enable machine learning with artificial neural networks”.</p>]]></content><author><name></name></author><category term="go_big" /><summary type="html"><![CDATA[What is Machine Learning 机器学习是一种让计算机模拟人脑从数据中学习并做出决策的过程，而不是过去那样利用计算机通过明确的编程指令完成特定任务。]]></summary></entry><entry><title type="html">末日生存指南</title><link href="http://localhost:4000/reading/2024/10/08/survival.html" rel="alternate" type="text/html" title="末日生存指南" /><published>2024-10-08T00:00:00+08:00</published><updated>2024-10-08T00:00:00+08:00</updated><id>http://localhost:4000/reading/2024/10/08/survival</id><content type="html" xml:base="http://localhost:4000/reading/2024/10/08/survival.html"><![CDATA[<p><a href="https://www.maicuole.com/discriminate/doomsday-survival-guide.html">Read Original</a></p>

<table>
  <tbody>
    <tr>
      <td>date_saved: 2024-10-08 10:03:16</td>
      <td>date_published:2023-07-20 16:46:43</td>
    </tr>
  </tbody>
</table>

<p>末日来临的话，你大体上需要预备四样东西：应急策略、物资、技能、伙伴。下面挨个谈谈这四样东西。</p>

<h2 id="01-应急策略"><strong>01. 应急策略</strong></h2>

<p>无论是核战争还是飓风，金融大崩溃还是海啸，超级细菌还是丧尸病毒，如果真的发生，大体情形都非常类似。人为灾变可以引起自然灾变，自然灾变可以引起人为灾变。一旦建立在现代消费社会的文明遭到破坏，物资会匮乏，水电供应停止，很快传染性疾病就会爆发。昨天的抢购就会变成今天的抢劫，后天的杀人越货，大后天的…… 由于大部分人生活在城市中，而城市的生存极端依赖商业体系维护，在公路大堵车、电力中断的情况下，大多数物资很快会枯竭，在这种情况下，你的应急策略大体上有两个：</p>

<p><strong>原地生存，苦撑待变；赶紧逃命，远走高飞。</strong></p>

<p>这两个策略并不决然对立。原地生存是相对最简单的办法，但在物资紧张、环境恶化后也必须考虑出逃。出逃的结果依然是寻找定居点，绝大多数人休想在完全野外的环境中长期生存，所以你最好前往事先设定为藏身之处的乡下小屋、亲友家、甚至是一个废弃工厂或仓库。</p>

<p>而在这两者中间，是考虑五十至八十公里路程附近人口稀少的郊区。这可以给你更多平时准备的机会。</p>

<p>而在背包之外，为了预备哪天上班路上天降伟人。你需要 “EDC”，即 “everyday carry”，也就是每天外出不可或缺的用品，帮助你能安全地逃回家里拿背包。</p>

<p>限于篇幅，<strong>本文只讲赶紧逃命和就地求存的情况。</strong></p>

<p>赶紧逃命，这方面有一本非常实用的书《逃生背包》(ISBN: 9787020173761)。</p>

<p>首先你得有一个六十升左右的好背包。策略方面，大体上讲如果出逃，自备车显然是不错的选择，但考虑到时公路可能堵塞，所以你选择的逃亡目的地不应该太远。一般在七十二小时步行距离内，按照一个人每小时走五公里的速度，一天走十个小时，三天就是一百五十公里。考虑到你需要携带大量物资装备，尤其是和家中的老幼同行，所以可能三天只能走一百公里。这是个什么概念呢：从上海出发，走一百公里可以到苏州或嘉兴，走一百五十公里可以到无锡或湖州（若想到常州和杭州，大概要走一百八十公里）。</p>

<p>坏消息是这几个地方山林不多，闹长毛那几年死人情况大抵是这样的，你们感受一下。</p>

<p><img src="https://www.maicuole.com/wp-content/uploads/2020/03/doomsday-survival-guide-01.jpg" alt="太平天国战争前后浙江省分府人口的变动" /></p>

<p>选择原地生存的话，你需要想象你所熟悉的一切商业文明都消失的状态，一分钟…… 然后深呼吸，是不是突然觉得现在花些钱存一点好划算？</p>

<p>在所有策略之前，是一条至理名言：你不是要摆酷。所以尽量低调、低调、低调！</p>

<p>具体策略包括：</p>

<p>不被饿死的多项物资：水、食物、燃料；不让疾病找上门的措施：卫生、医疗；不被人抢劫或干掉的办法：武器、陷阱、预警系统；如果你活得足够长，还可以考虑恢复人类文明：比如发电、通讯……</p>

<p>如果你还在准备应急包、家庭应急物资之类的东西，可以参考我下面的这个清单，涵盖 200 余种物品。</p>

<p><a href="https://downloads.maicuole.com/PDF/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E7%9A%84%E5%AE%B6%E5%BA%AD%E5%BA%94%E6%80%A5%E7%89%A9%E8%B5%84%E5%82%A8%E5%A4%87%E6%B8%85%E5%8D%95%EF%BC%88%E4%B9%B0%E9%94%99%E4%BA%86%E7%BD%91%EF%BC%89.pdf">下载 PDF 版</a></p>

<h2 id="02-物资"><strong>02. 物资</strong></h2>

<p>再次推荐《逃生背包》一书，里面策略、技能的内容确实不多，但物资储备的内容比较全，虽然是为七十二小时大逃亡准备的，但原地生存在物资类别上基本是重合的，因而可以借鉴。</p>

<p>现在让我们来划一下重点。</p>

<p><strong>首先得保证充足的饮用水。</strong> 一个成年人每天的饮水量在二升左右，夏天会多一点。无论原地生存还是逃命，你都需要很多水。</p>

<p>原地生存的话，务必多备储水容器，在有警报或者坏新闻时装满家里的储水容器，即使没有预警时，也应该装满一些容器定期更换。同时购买或自己灌装瓶装、桶装水。</p>

<p>应该至少储备每人两周的饮用水，即每人三十升。之所以要预备两周的时间是因为大多数人这个时候已经挂掉，你出外寻找物资会安全一点。当然能多放一点是更好的。储存时，应该避免阳光照射滋生水藻。也不要放在阁楼、露台等地方，可能会压塌掉。做好记录，定期更换。</p>

<p><img src="https://www.maicuole.com/wp-content/uploads/2020/03/doomsday-survival-guide-03.jpg" alt="不锈钢水壶" /></p>

<p><strong>水具要铝制或不锈钢水壶，不要中空保温的。</strong>因为很多时候你需要用水壶直接加热煮沸（最好有折叠长柄）。<strong>必要的其他储水装置，比如柔性睡袋。</strong>用完可以卷起来。适合逃亡。</p>

<p>如果要出逃，按照七十二小时计划，一个人应该至少携带五升水，<strong>前提是你同时有便携式净水器或净水药片</strong>，而且沿途确实有比较清澈的水源。净水药片也应该按照可净化水量储备相应的量，但这玩意儿很轻，你不必担心超重，可以多带一点，甚至在关键时刻当货币用。</p>

<p>清洗用水也非常重要。其中最重要的是洗手，大多数疾病会通过手传播。考虑到排泄污物的泛滥，手会有更大机会沾染致病菌。而此时水已经非常宝贵。<strong>你可以考虑购买更多手套和免水消毒液来洗手。</strong> 或者用小杯子慢慢倒的方法尽可能省水地洗手。洗澡可以主要靠下雨，很酷，不是吗？如果用储备水洗澡，一定保证伤员优先。衣物要定期清洗晾晒。</p>

<p><strong>要有足够的食物，重要原则：保质期长。逃命的话，热量高。原地的话，营养全。</strong></p>

<p>比如，<strong>压缩饼干</strong>，提供碳水化合物，是很好的能量来源。坏处是营养单一，很容易引起一些营养缺乏症。<strong>罐头</strong>，能储存很长时间，但使用复杂，需要专门的刀具，而且大多数需要加热。（加热可以用微波炉 —— 这是不可能的，你得加热水，把罐头放在热水中。记得顶上开孔跑气）<strong>开袋自热食品</strong>，这些应该留足给最后出逃用，相比罐头，它的使用更方便，相比压缩饼干，它的营养更全面。</p>

<p>其他：能量棒、奶粉、蛋白粉、燕麦、红糖、蜂蜜。</p>

<p><img src="https://www.maicuole.com/wp-content/uploads/2020/03/doomsday-survival-guide-04.jpg" alt="食物" /></p>

<p><strong>烹饪器材也需留心：铝制的锅子、杯子</strong>，无论是在原地还是逃亡，你都需要加热食品，尤其是饮用水；<strong>燃料</strong>，固体酒精、液化气便携装适合逃亡，家用液化气、液体酒精、燃油、木头、煤适合原地。数量多少很难确定，要看水质和天气。你需要做好很快要拆家具烧的准备。其他必备：<strong>开罐刀</strong>，当然最好是组合工具，可以多用途。勺子或者筷子。取火，打火机一打，考虑到易损耗，应该备用一些镁条打火棒。<strong>便携炉</strong>，你储备什么燃料就配套什么炉子，主要是，压缩燃气和直接点。建议都备。</p>

<p><strong>保证有得穿。</strong> 如果采取原地策略，衣物一般不会成为问题。如果逃亡，应该至少有两套衣物，内衣可以适当再增加，袜子至少四双。挑选原则是：速干、耐用、宽松、适合季节、颜色黯淡（低调！记得吧）。《逃生背包》认为牛仔裤很不合适出逃，因为棉布吸潮，很难干，建议用混纺的。</p>

<p><strong>鞋子要选登山靴或远足鞋</strong>，请务必之前穿软了！想想你可能要走 100 多公里，帽子，遮阳、挡雨、低调；雨披，合适的雨披有多种用途，可以搭帐篷、当地垫，即使没有下雨，它也有助于你清晨防止露水，甚至取代普通外套来御寒。手套，御寒手套和工作手套，有些人家里可能已经没有工作手套了，这可能是这部分唯一家里一般找不到的东西。所以对于原地求生也很重要，你不希望自己挖坑、劈柴的时候把手弄破皮的，这种时候的任何伤病都可能是致命的。其他保护：太阳镜、口罩。</p>

<p><img src="https://www.maicuole.com/wp-content/uploads/2018/09/outdoor-camping-tent-003.jpg" alt="天幕帐" /></p>

<p><strong>住的话</strong>，原地住的问题不大，但仍要考虑到可能需要加固的一些场所。这里主要讲出逃，帐篷布、帐篷、睡袋、铝箔求生毯、泡沫睡垫都是必须的。</p>

<p><strong>还有药品</strong>，复合维生素、阿司匹林（当然中药爱好者，请替换成板蓝根）、急救套装（包含外伤的一系列用品。创可贴、绷带等碘酒务必要有，不仅能处理外伤，还能处理饮用水，因为很多时候你根本没时间烧开水喝。）胃肠药、皮肤药膏、治过敏（扑尔敏、息斯敏）眼药水（用完了瓶子也别扔，很有用）、驱虫剂、橡胶手套、牙刷牙膏牙线（不会再有牙医诊所了。想一想《荒岛余生》里面汤姆汉克斯因为牙痛，不得不把用石头把牙砸掉，爱护牙齿吧）、纸巾、洗衣粉、肥皂、84 消毒液。</p>

<p><strong>最重要的还有武器</strong>，就是可以用来攻击其他动物和人类的东西。你越是希望保持文明状态，就越需要武器，两个都拿原子弹的人打起来的可能性几乎没有。当然，原则仍然是“低调”！不怕坏人抢，就怕坏人惦记。清单如下：</p>

<ul>
  <li>渔具包</li>
  <li>野营刀</li>
  <li>丛林刀（相对不容易买到）</li>
  <li>手斧。有一本青少年求生书就叫《手斧男孩》</li>
  <li>消防破拆斧（适合原地）</li>
  <li>长短棍。就地求生可以常备。</li>
</ul>

<p><strong>照明、信息：</strong></p>

<ul>
  <li>手电筒、头灯、蜡烛。</li>
  <li>望远镜。</li>
  <li>地图、指南针。</li>
  <li>收音机、对讲机。</li>
  <li>相应的电池、手摇发电机。如果倾向于原地求生，则提前改装自行车做发电机。</li>
</ul>

<p><img src="https://www.maicuole.com/wp-content/uploads/2020/03/doomsday-survival-guide-05.jpg" alt="多功能工具" /></p>

<p><strong>无法归类的多功能工具：</strong></p>

<ul>
  <li>多功能刀具。带钳子、螺丝刀、罐头刀、锯子等。</li>
  <li>线锯。最方便携带的锯子，逃亡路上锯树。也可以作为陷阱材料。</li>
  <li>密封袋。放重要物品。火种、药品、地图等。</li>
  <li>垃圾袋。不是很薄的那种。要厚黑型！</li>
  <li>N95。中国人民的老朋友，不仅能在烟尘中保护呼吸系统，还能用来过滤饮用水，但不要买带呼吸阀的款式。</li>
  <li>绳索。非常重要。无论原地还是逃亡。推荐 550 伞绳。</li>
  <li>针线包。再也没有淘宝让你买衣服了。还可以拔牙和给自己缝皮。</li>
  <li>胶带。不推荐透明胶带。布基胶带要有用的多。补帐篷、工具、武器……</li>
  <li>安全套。别多想，这玩意儿可以装水。可以作为很好的密封袋。还可以套住穿好袜子的脚，保持脚部干燥。脚完了，你就别想逃亡了。</li>
  <li>卫生巾。很好的引火材料。在很多户外环境下，即使你有火种、木材。但因为潮湿还是点不着。所以需要很容易燃烧的材料先烧起来再点着木头。另外，它的吸水性非常好，超过所有手帕、口罩。可以在火灾或其他需要有毒烟尘情况下可以打湿保护呼吸道。</li>
  <li>塑胶管。可以止血、捆扎、取水、做弹弓……</li>
  <li>纸、笔、镜子。</li>
  <li>工兵铲。原地时种植，出外当武器。</li>
</ul>

<p><img src="https://www.maicuole.com/wp-content/uploads/2020/03/doomsday-survival-guide-06.jpg" alt="手套等物品" /></p>

<h2 id="03-技能"><strong>03. 技能</strong></h2>

<p>可以参考《怀斯曼生存手册》(ISBN: 9787531721666)。</p>

<p>原则：上述物资的使用和保存方法。</p>

<p><strong>食：</strong></p>

<ul>
  <li>食品保存技能。定期检查、更换制度，定期给罐头翻动，避免罐头析出、沉淀。</li>
  <li>野外饮水获取。你要考虑到你携带的滤水器可能损害失效。所以必须学会用自然材料滤水的方法。</li>
  <li>捕猎设陷阱的技能。包括制造武器的技能。</li>
  <li>多种取火的技能。打火石、钻木取火、火犁等。营地火堆的搭建。炉灶的搭建。</li>
  <li>识别野生可食用植物的技能。</li>
  <li>处理食物的方法。腌制、熏制。</li>
  <li>给猎物剥皮、烹饪的能力。</li>
  <li>长期原地求生还需要会种植蔬菜粮食的技能。</li>
</ul>

<p><strong>住：</strong></p>

<ul>
  <li>绳索打结的方法。</li>
  <li>搭建避难所的技能。如果你采用帐篷布，你也需要知道如何架设。更多情况下，你需要完全从自然界就地取材。比如用大量松枝充当防潮垫。</li>
  <li>石器。考虑到你可能被打劫地什么也不剩。所以多功能小刀会和你永别。你需要向我们的智人祖先学习宝贵石器技术。制作石斧石刀等工具。</li>
</ul>

<p><strong>行：</strong></p>

<ul>
  <li>绳索打结的方法。</li>
  <li>识别地图。多种辨识方向的技能。</li>
  <li>识别天气的能力。</li>
  <li>修车的技能。</li>
</ul>

<p><img src="https://www.maicuole.com/wp-content/uploads/2020/03/doomsday-survival-guide-07.jpg" alt="医疗用品" /></p>

<p><strong>医：</strong></p>

<ul>
  <li>外伤处理</li>
  <li>人口呼吸、心脏复苏</li>
  <li>野外分娩</li>
  <li>排泄物和尸体的掩埋处理</li>
</ul>

<p><strong>防卫：</strong></p>

<ul>
  <li>体能。</li>
  <li>武器的使用。包括前面说的自制武器。</li>
  <li>建议长期学搏击。虽然大多数末日战斗都不会赤手空拳，但学过的人灵活度、体能上会更有优势。而且你会比普通人更熟悉人体的脆弱部位。</li>
</ul>

<h2 id="04-伙伴"><strong>04. 伙伴</strong></h2>

<p>即使你拥有了以上所有。都可能不如一群朋友来的重要，甚至有时只是一个朋友。即使你拥有所有技能，你也必须睡觉，你需要伙伴的保护。何况你不可能掌握所有技能，你需要其他人的合作共赢。更重要的是，你需要他们告诉你，依然有人在坚守文明的价值，人类作为一个族群并没有消失。你不仅仅是为了一个自己活着，你更是作为人类文明社会的一分子活下去，战斗下去。你不是在延续不断地苟活，你是要和这样的一群人一起迎接人类文明社会的再次重建。所以你最好平时能说服几个好友一起储备、计划、训练。</p>

<p>当然，如果你实在找不到合适的地球人。汪星人是很好的替代方案。</p>

<p>应该说，正在看这条微信的你，几乎都是过惯太平日子的人。我们认为这样的生活理所当然，却不知平和不过是争战的假象。且不说世界上还有多少地方战火纷飞，和我们一样的人就像稻草一样被收割屠宰却根本无人在乎；就是在我们日常生活的市镇，夜深人静之时也会发生触目惊心的暴力事件。现代世界就像一栋纸牌屋，看似有序华丽，却异常脆弱，只要抽掉一张，所有的一切就都会崩溃。到时，很多像你我一样沉溺于“日常生活”的人，恐怕连喊都喊不出一声，就会被暴力的洪水淹没；要么，就成为无序暴力的一份子。</p>

<p>如果你准备预先体验一把末日生存，不妨看看这本《〈汤姆・克兰西：全境封锁〉艺术设定集》(ISBN: 9787513322133)，对滔天“洪水”洗刷后的世界有个大概的印象也不错。</p>]]></content><author><name></name></author><category term="reading" /><summary type="html"><![CDATA[Read Original]]></summary></entry><entry><title type="html">Tombkeeper on Musk</title><link href="http://localhost:4000/reading/2024/10/06/tombkeeper_on_musk.html" rel="alternate" type="text/html" title="Tombkeeper on Musk" /><published>2024-10-06T00:00:00+08:00</published><updated>2024-10-06T00:00:00+08:00</updated><id>http://localhost:4000/reading/2024/10/06/tombkeeper_on_musk</id><content type="html" xml:base="http://localhost:4000/reading/2024/10/06/tombkeeper_on_musk.html"><![CDATA[<blockquote>
  <p>马斯克的目标不是盖茨贝索斯，是凯撒哥伦布罗伯斯庇尔。 ——<a href="https://weibo.com/1401527553/JFr2qsBRy">Source</a></p>
</blockquote>

<blockquote>
  <p>马斯克的情况，我感觉简单描述的话就是中年危机。当然，他这种人的中年危机和咱们不一样，不是买辆法拉利就能缓解的。
马斯克是 1971 年的，去年刚好 50。他可能意识到之前把火星殖民的事儿想简单了，也把脑机接口的事儿想简单了。于是感觉自己有生之年没办法通过搞火星殖民来重建一个理想社会，也没办法通过脑机接口来延长自己的有生之年。这年月，揭竿而起很不现实。那么人生剩下的时间推动社会变革最可行的路径就是数字技术和社交媒体了。
这大概就是他买了 twitter 这种赔钱货还特别上心，而疏于经营特斯拉的原因。他这类人的成就感阈值非常高，新能源革命对他来说是远远不够的。 ——<a href="https://weibo.com/6827625527/Mkl31845x">Source</a></p>
</blockquote>

<p>“As you can see, I’m not just MAGA – I’m dark MAGA,” Musk quipped.</p>

<p>He then compared Trump with President Joe Biden, saying that Biden “could’t climb a flight of stairs” while Trump “was fist pumping after getting shot,” referring to the July assassination attempt that left the former president wounded in the ear.</p>

<blockquote>
  <p>我以前说过，马斯克有巨大的政治理想。然而他出生在南非，永远当不了美国总统。
所以他今天在川普竞选集会上的<a href="https://x.com/cb_doge/status/1842702850968744174">表现</a>也并不令人意外，和他近几年干的事算是一以贯之。——<a href="https://weibo.com/6827625527/OAgZlljOs">Source</a></p>
</blockquote>]]></content><author><name></name></author><category term="reading" /><summary type="html"><![CDATA[马斯克的目标不是盖茨贝索斯，是凯撒哥伦布罗伯斯庇尔。 ——Source]]></summary></entry><entry><title type="html">此时不搏，更待何时？</title><link href="http://localhost:4000/blog/2024/09/27/higher_highs.html" rel="alternate" type="text/html" title="此时不搏，更待何时？" /><published>2024-09-27T00:00:00+08:00</published><updated>2024-09-27T00:00:00+08:00</updated><id>http://localhost:4000/blog/2024/09/27/higher_highs</id><content type="html" xml:base="http://localhost:4000/blog/2024/09/27/higher_highs.html"><![CDATA[<p>一切运动式行为都不倾向于有好的结果，好结果的背后通常是实事求是、以人为本为出发点。</p>

<p>这周二以来，中国央行出了两个政策，一个是将存量房贷利率下调0.5%、降低二套住房首付比例；第二是针对股市，为企业提供股票回购再贷款、允许有资质企业用股票和央行置换国债，卖出国债继续买入股票。加上昨天召开的政治局会议中透露出要促进房地产止跌回稳。一连串政策通知，让上证指数三天从2700多冲上3000点。港股、美股中概也复制了疯狂行情，外资接连唱多。</p>

<p>发展经济要真这么简单就好了，借钱给企业买股票就能使经济繁荣，左脚踩右脚想要跳得更高。运动式行情可以刺激短期经济，市场上确实也缺这种活力。但问题不在于这些刺激政策是否正确，而在于后续能否有更多保障民生的就业、住房、医疗、养老等和人民群众利益切实相关的改革措施跟上。能否真正提高人民收入、改善未来预期。否则，可能又是一次击鼓传花的游戏，钱最终流向了不缺钱的人。</p>

<p>历史经验告诉我们，在这种疯狂中唯一能做的就是做好自己的事，观察，冷静做下任何决定。</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[一切运动式行为都不倾向于有好的结果，好结果的背后通常是实事求是、以人为本为出发点。]]></summary></entry><entry><title type="html">About Running</title><link href="http://localhost:4000/blog/2024/09/25/about_running.html" rel="alternate" type="text/html" title="About Running" /><published>2024-09-25T00:00:00+08:00</published><updated>2024-09-25T00:00:00+08:00</updated><id>http://localhost:4000/blog/2024/09/25/about_running</id><content type="html" xml:base="http://localhost:4000/blog/2024/09/25/about_running.html"><![CDATA[<p>Q: 你为什么会开始跑步？（与其说开始跑，突破极限的感觉）</p>

<p>A: 在我看来，跑步是所有运动的基础，任何体育项目要想有优异的表现都需要有足够的体能储备。所以与其说我为什么开始跑步，不如说我顺其自然地去跑了步。另外，当突破自己身体极限之后给我的感觉非常舒服。</p>

<p>Q: 跑步给你带来了什么？（枯燥，talking to myself，最重要的资产）</p>

<p>A: 跑步，特别是长跑，是一项枯燥的运动，这也是以前很多年轻群体不会把跑步作为首选运动的原因，但是我想说，跑步的好处之一，就是可以有个机会与自己的身体、内心进行交流。跑步给我带来了一副强大的身体和意志，这是我在任何情况下最重要的资产。</p>

<p>Q: 跑步让你生活有什么改变？（好的状态，高效生活工作，不会退缩）</p>

<p>A: 跑步让我的身体能保持一个好的状态，让我的工作和生活都更加高效。当一个人和自己的身体达成了共识，生活中还有什么困难能真正让他退缩呢？</p>

<p>Q: 一个人跑和一群人跑区别？（了解自己，鼓励、建议，特殊的满足感）</p>

<p>A: 一个人跑是一个和自己对话、更了解自己的过程。而一群人跑则可以相互鼓励，训练时遇到的瓶颈和可能的问题也能得到团队有效的建议。另外，在团队中获得成就也更能带来一种特殊的满足感。</p>

<p>Q: 跑步的目标？（更好的生活，感染身边的人，pb 水到渠成）</p>

<p>A: 就我个人而言，跑步的首要目标是为了能更好地生活，如果能带动身边的家人、同事一起养成健康的生活方式那就更好了。至于pb嘛，当你充分训练了，那是水到渠成的事。</p>

<p>Q: 跑步得到了什么？（一口气上五楼）</p>

<p>A: 一口气上五楼，不费劲儿。</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[Q: 你为什么会开始跑步？（与其说开始跑，突破极限的感觉）]]></summary></entry><entry><title type="html">日本人学校遇害学生父亲的信</title><link href="http://localhost:4000/reading/2024/09/21/japanese_children_in_china.html" rel="alternate" type="text/html" title="日本人学校遇害学生父亲的信" /><published>2024-09-21T00:00:00+08:00</published><updated>2024-09-21T00:00:00+08:00</updated><id>http://localhost:4000/reading/2024/09/21/japanese_children_in_china</id><content type="html" xml:base="http://localhost:4000/reading/2024/09/21/japanese_children_in_china.html"><![CDATA[<p>2024年6月24日，中国苏州，一辆载有放学回家的日本孩子的校车抵达距学校近一公里外的车站时，一位 “不清楚作案动机” 的52岁男子试图上车袭击学生，55岁的校车乘务员胡友平在阻拦过程中被刺身亡。</p>

<p>2024年9月18日，中国深圳，一名5年级日本男学生在距离学校200米处，遭一名44岁中国男子持刀袭击，经抢救无效死亡。</p>

<p>前一个事件以“宣扬胡友平英勇无畏、弘扬社会正气”为终，后一个事件以“就核废水排海达成共识，中国恢复进口日本水产”试图画上句号。当然它们会有一个共同点，那就是和东航737客机坠毁一样，永远等不到官方调查通报。</p>

<p>昨天还观察到一个事情，遇害男学生的父亲小山纯平的一封写给领事馆的信的截图在中文互联网被大面积移除。</p>

<p>我很好奇，他们何以心虚至此，以至于如此义无反顾地站在人类良善、同理及一切进步的品质的对立面。以及浩浩荡荡的义和团运动和人类踏上火星开启多星系物种时代，哪一个会先到来？</p>

<p>做个记录。</p>

<p>形势一片大好，不是小好，是大好。一切正越来越好。</p>

<blockquote>
  <p>力石先生、古家先生</p>

  <p>感谢您昨日一直陪伴到很晚。</p>

  <p>关于领事馆和公司的评论，您可以自行决定。但我还是希望您能了解我的心情，因此写下了这封信。或许更多是为了整理我的情绪，可能有些地方写得不够好，还请见谅。是否转发、以及转发给谁，都请您自由决定。</p>

  <p>航平非常喜欢昆虫和爬行动物，是个拥有独特眼力，能发现任何小生物的孩子。他拥有比任何人都更为温柔的心灵。从小就喜欢画画，是一个对语言很有天赋的孩子，能够流利地使用日语和中文。</p>

  <p>他一直对随我前往深圳的安排感到犹豫不决。由于偏食，他一开始很难适应当地的饮食，但最近，他喜欢上了越来越多的中国食物，并且迷上了刚刚开始的篮球运动。</p>

  <p>他如此突然地离开了我们，我完全没有料到。现在，我的内心充满了困惑和无尽的悲痛。我再也无法看到他如何成长，如何成为大人。无法保护他，这将成为我一生都无法释怀的悔恨。</p>

  <p>航平既是日本人，也是中国人。他的母亲是中国人，曾在日本生活了近十年；他的父亲是一个已经在中国度过了将近一半人生的日本人。航平本人三岁前的大部分时间都是在中国妻子的家中度过的。无论外界如何报道，他拥有日本和中国两国根源的事实不会改变。</p>

  <p>我们不会憎恨中国，同样，我们也不会憎恨日本。</p>

  <p>无论国籍为何，我们都将这两个国家视为自己的国家。尽管风俗和文化存在差异，但我们比谁都清楚，大家都是一样的人。因此，我不希望由极少数持扭曲思想的卑劣之人的罪行，来破坏两国的关系。我唯一的愿望就是，这样的悲剧不再重演。</p>

  <p>航平曾经有一次对我说：“将来想成为像爸爸一样的人。”或许这只是一时的心血来潮，但作为父亲，这句话让我无比欣慰。我从事中日贸易的工作，担任着日本和中国之间的桥梁。我的主要职责是弥合双方的认知差异，促进顺畅的沟通。</p>

  <p>如果没有发生这次不幸的事件，我相信他一定会成为比我更有用的人。但现在，我只能尽全力成为一个他可以为之自豪的人，并且，继续为日中两国的相互理解作出微小的贡献，这既是对我最爱的儿子的赎罪，也是对犯人的报复。</p>

  <p>最重要的是，我想对航平表示感激，感谢他让我们成为父母，感谢他在我们身边度过了10年8个月又7天的时光。我们将会继续坚强地生活下去，为他，继续走完他未完成的路。</p>

  <p>小山纯平</p>
</blockquote>]]></content><author><name></name></author><category term="reading" /><summary type="html"><![CDATA[2024年6月24日，中国苏州，一辆载有放学回家的日本孩子的校车抵达距学校近一公里外的车站时，一位 “不清楚作案动机” 的52岁男子试图上车袭击学生，55岁的校车乘务员胡友平在阻拦过程中被刺身亡。]]></summary></entry><entry><title type="html">Hands on Delta Lake</title><link href="http://localhost:4000/go_big/2024/09/19/delta_lake.html" rel="alternate" type="text/html" title="Hands on Delta Lake" /><published>2024-09-19T00:00:00+08:00</published><updated>2024-09-19T00:00:00+08:00</updated><id>http://localhost:4000/go_big/2024/09/19/delta_lake</id><content type="html" xml:base="http://localhost:4000/go_big/2024/09/19/delta_lake.html"><![CDATA[<h3 id="what-is-delta-lake">What is Delta Lake</h3>
<p><a href="https://delta.io/">Delta Lake</a> 是一个开源的数据湖存储层 (lakehouse storage layer) 技术，它利用基于文件的事务日志 (file-based transaction log) 扩展了 <a href="https://parquet.apache.org/">Parquet</a> 数据文件，以实现 ACID 事务和可扩展的元数据处理。Delta Lake 与 Apache Spark API 完全兼容，专为与 Structured Streaming 集成而开发，可以很方便地对 batch &amp; streaming 数据进行处理。</p>

<p>Delta Lake 的主要优势是它对大规模数据处理的可靠性和一致性，同时提供了类似于传统数据库的事务功能。在使用过程中可以通过 Spark SQL 来读取、写入和管理 Delta Lake 中的数据。下面将这些功能一一演示。</p>

<h3 id="how-to-use-delta-lake">How to Use Delta Lake</h3>
<h4 id="install-delta-packege">Install Delta Packege</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>delta-spark<span class="o">==</span>2.1.0
</code></pre></div></div>

<h4 id="load-delta-related-jars-from-maven-repo">load delta related jars from maven repo</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pyspark <span class="nt">--packages</span> io.delta:delta-core_2.12:2.1.0 <span class="se">\</span>
<span class="nt">--conf</span> <span class="s2">"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension"</span> <span class="se">\</span>
<span class="nt">--conf</span> <span class="s2">"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"</span> <span class="se">\</span>
<span class="nt">--conf</span> <span class="s2">"hive.tez.input.format=io.delta.hive.HiveInputFormat"</span>
</code></pre></div></div>

<h4 id="set-up-a-python-project">Set up a Python Project</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">delta</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">builder</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">DeltaDemo</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.extensions</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">io.delta.sql.DeltaSparkSessionExtension</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.catalog.spark_catalog</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">org.apache.spark.sql.delta.catalog.DeltaCatalog</span><span class="sh">"</span><span class="p">)</span>

<span class="n">spark</span> <span class="o">=</span> <span class="nf">configure_spark_with_delta_pip</span><span class="p">(</span><span class="n">builder</span><span class="p">).</span><span class="nf">getOrCreate</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="create-a-table">Create a Table</h4>
<p><strong>1. Using Spark SQL DDL</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
create or replace table {your_database}.delta_demo(
    id int, 
    firstName string, 
    middleName string, 
    lastName string, 
    gender string, 
    birthDate date, 
    ssn string, 
    salary int)
using delta 
location </span><span class="sh">'</span><span class="s">s3://{S3_BUCKET}/delta_demo</span><span class="sh">'</span><span class="s">;
</span><span class="sh">"""</span><span class="p">)</span>

<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"</span><span class="s">drop table {your_database}.delta_demo</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>2. Using Exsiting Spark Dataframe and change the format to delta</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="append-data">Append Data</h4>
<p><strong>Write data from existing Spark Dataframe</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">date</span>

<span class="n">schema</span> <span class="o">=</span> <span class="nc">StructType</span><span class="p">([</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">,</span> <span class="nc">IntegerType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">firstName</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">middleName</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">lastName</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">birthDate</span><span class="sh">"</span><span class="p">,</span> <span class="nc">DateType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">ssn</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
  <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">salary</span><span class="sh">"</span><span class="p">,</span> <span class="nc">IntegerType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
  <span class="p">(</span><span class="mi">9999998</span><span class="p">,</span> <span class="sh">'</span><span class="s">Billy</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Tommie</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Luppitt</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1992-09-17</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">953-38-9452</span><span class="sh">'</span><span class="p">,</span> <span class="mi">55250</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">9999999</span><span class="p">,</span> <span class="sh">'</span><span class="s">Elias</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Cyril</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Leadbetter</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1984-05-22</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">906-51-2137</span><span class="sh">'</span><span class="p">,</span> <span class="mi">48500</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">10000000</span><span class="p">,</span> <span class="sh">'</span><span class="s">Joshua</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Chas</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Broggio</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1968-07-22</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">988-61-6247</span><span class="sh">'</span><span class="p">,</span> <span class="mi">90000</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">20000001</span><span class="p">,</span> <span class="sh">'</span><span class="s">John</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="sh">'</span><span class="s">Doe</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1978-01-14</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">345-67-8901</span><span class="sh">'</span><span class="p">,</span> <span class="mi">55500</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">20000002</span><span class="p">,</span> <span class="sh">'</span><span class="s">Mary</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="sh">'</span><span class="s">Smith</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1982-10-29</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">456-78-9012</span><span class="sh">'</span><span class="p">,</span> <span class="mi">98250</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">20000003</span><span class="p">,</span> <span class="sh">'</span><span class="s">Jane</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="sh">'</span><span class="s">Doe</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">,</span> <span class="n">date</span><span class="p">.</span><span class="nf">fromisoformat</span><span class="p">(</span><span class="sh">'</span><span class="s">1981-06-25</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">567-89-0123</span><span class="sh">'</span><span class="p">,</span> <span class="mi">89900</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">data_insert</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
<span class="n">data_insert</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">append</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">{S3_BUCKET}/delta_demo</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="read-table">Read Table</h4>
<p><strong>1. Read Delta table name</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">delta_demo_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">table</span><span class="p">(</span><span class="sh">"</span><span class="s">{your_database}.delta_demo</span><span class="sh">"</span><span class="p">)</span>
<span class="n">delta_demo_df</span><span class="p">.</span><span class="nf">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>firstName</th>
      <th>middleName</th>
      <th>lastName</th>
      <th>gender</th>
      <th>birthDate</th>
      <th>ssn</th>
      <th style="text-align: left">salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>9999998</td>
      <td>Billy</td>
      <td>Tommie</td>
      <td>Luppitt</td>
      <td>M</td>
      <td>1992-09-17</td>
      <td>953-38-9452</td>
      <td style="text-align: left">55250</td>
    </tr>
    <tr>
      <td>9999999</td>
      <td>Elias</td>
      <td>Cyril</td>
      <td>Leadbetter</td>
      <td>M</td>
      <td>1984-05-22</td>
      <td>906-51-2137</td>
      <td style="text-align: left">48500</td>
    </tr>
    <tr>
      <td>20000002</td>
      <td>Mary</td>
      <td> </td>
      <td>Smith</td>
      <td>F</td>
      <td>1982-10-29</td>
      <td>456-78-9012</td>
      <td style="text-align: left">98250</td>
    </tr>
    <tr>
      <td>20000003</td>
      <td>Jane</td>
      <td> </td>
      <td>Doe</td>
      <td>F</td>
      <td>1981-06-25</td>
      <td>567-89-0123</td>
      <td style="text-align: left">89900</td>
    </tr>
    <tr>
      <td>10000000</td>
      <td>Joshua</td>
      <td>Chas</td>
      <td>Broggio</td>
      <td>M</td>
      <td>1968-07-22</td>
      <td>988-61-6247</td>
      <td style="text-align: left">90000</td>
    </tr>
    <tr>
      <td>20000001</td>
      <td>John</td>
      <td> </td>
      <td>Doe</td>
      <td>M</td>
      <td>1978-01-14</td>
      <td>345-67-8901</td>
      <td style="text-align: left">55500</td>
    </tr>
  </tbody>
</table>

<p><strong>2. Read Delta table by specifying the path to the file</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="update-table">Update Table</h4>
<p><strong>1. Using Spark SQL DML</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
UPDATE {your_database}.delta_demo SET gender = </span><span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="s"> WHERE gender = </span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="s">
</span><span class="sh">"""</span><span class="p">)</span>
<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
UPDATE {your_database}.delta_demo SET gender = </span><span class="sh">'</span><span class="s">Male</span><span class="sh">'</span><span class="s"> WHERE gender = </span><span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="s">
</span><span class="sh">"""</span><span class="p">)</span>
<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
CREATE OR REPLACE TEMP VIEW upsert_view (
  id, firstName, middleName, lastName, gender, birthDate, ssn, salary
) AS VALUES
  (9999998, </span><span class="sh">'</span><span class="s">Billy</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Tommie</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Luppitt</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">1992-09-17</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">953-38-9452</span><span class="sh">'</span><span class="s">, 55250),
  (20000003, </span><span class="sh">'</span><span class="s">Jane</span><span class="sh">'</span><span class="s">, </span><span class="sh">''</span><span class="s">, </span><span class="sh">'</span><span class="s">Doe</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">1981-06-25</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">567-89-0123</span><span class="sh">'</span><span class="s">, 89900)
</span><span class="sh">"""</span><span class="p">)</span>
<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
MERGE INTO {your_database}.delta_demo demo
USING upsert_view upsert
ON demo.id = upsert.id
WHEN MATCHED THEN UPDATE SET *
WHEN NOT MATCHED THEN INSERT *
</span><span class="sh">"""</span><span class="p">)</span>
<span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
DELETE FROM {your_database}.delta_demo WHERE birthDate &lt; </span><span class="sh">'</span><span class="s">1980-01-01</span><span class="sh">'</span><span class="s">
</span><span class="sh">"""</span><span class="p">)</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>firstName</th>
      <th>middleName</th>
      <th>lastName</th>
      <th>gender</th>
      <th>birthDate</th>
      <th>ssn</th>
      <th style="text-align: left">salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>9999998</td>
      <td>Billy</td>
      <td>Tommie</td>
      <td>Luppitt</td>
      <td>M</td>
      <td>1992-09-17</td>
      <td>953-38-9452</td>
      <td style="text-align: left">55250</td>
    </tr>
    <tr>
      <td>9999999</td>
      <td>Elias</td>
      <td>Cyril</td>
      <td>Leadbetter</td>
      <td>Male</td>
      <td>1984-05-22</td>
      <td>906-51-2137</td>
      <td style="text-align: left">48500</td>
    </tr>
    <tr>
      <td>20000002</td>
      <td>Mary</td>
      <td> </td>
      <td>Smith</td>
      <td>Female</td>
      <td>1982-10-29</td>
      <td>456-78-9012</td>
      <td style="text-align: left">98250</td>
    </tr>
    <tr>
      <td>20000003</td>
      <td>Jane</td>
      <td> </td>
      <td>Doe</td>
      <td>F</td>
      <td>1981-06-25</td>
      <td>567-89-0123</td>
      <td style="text-align: left">89900</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>注：
Delta Lake 为了解决数据的一致性和可靠性，引入了事务日志和元数据管理来实现 ACID 事务。</p>

  <p>Delta Lake 的物理构成主要是两部分：</p>
  <ol>
    <li>以 Parquet 格式存储在文件系统的数据文件，任何数据操作，数据文件只增不减；</li>
    <li>在数据文件的同级目录下，有一个文件夹专门存放 Json 格式的事务日志，它用来记录所有对数据的操作，每一次操作都会生成一个日志文件，记录这次操作的详细信息。</li>
  </ol>

  <p>基于以上架构，在每次读取 Delta Lake 数据时，会自动根据事务日志生成一个数据快照，并将该快照的结果返回成 Dataframe。</p>
</blockquote>

<p><strong>2. Using Delta Lake API</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">delta.tables</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">pyspark.sql.functions</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">deltaTable</span> <span class="o">=</span> <span class="n">DeltaTable</span><span class="p">.</span><span class="nf">forPath</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Update every even value by adding 100 to it
</span><span class="n">deltaTable</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span>
  <span class="n">condition</span> <span class="o">=</span> <span class="nf">expr</span><span class="p">(</span><span class="sh">"</span><span class="s">id % 2 == 0</span><span class="sh">"</span><span class="p">),</span>
  <span class="nb">set</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="nf">expr</span><span class="p">(</span><span class="sh">"</span><span class="s">id + 100</span><span class="sh">"</span><span class="p">)</span> <span class="p">})</span>

<span class="c1"># Delete every even value
</span><span class="n">deltaTable</span><span class="p">.</span><span class="nf">delete</span><span class="p">(</span><span class="n">condition</span> <span class="o">=</span> <span class="nf">expr</span><span class="p">(</span><span class="sh">"</span><span class="s">id % 2 == 0</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># Upsert (merge) new data
</span><span class="n">newData</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">deltaTable</span><span class="p">.</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">oldData</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">merge</span><span class="p">(</span>
    <span class="n">newData</span><span class="p">.</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">newData</span><span class="sh">"</span><span class="p">),</span>
    <span class="sh">"</span><span class="s">oldData.id = newData.id</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">whenMatchedUpdate</span><span class="p">(</span><span class="nb">set</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">newData.id</span><span class="sh">"</span><span class="p">)</span> <span class="p">})</span> \
  <span class="p">.</span><span class="nf">whenNotMatchedInsert</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">newData.id</span><span class="sh">"</span><span class="p">)</span> <span class="p">})</span> \
  <span class="p">.</span><span class="nf">execute</span><span class="p">()</span>

<span class="n">deltaTable</span><span class="p">.</span><span class="nf">toDF</span><span class="p">().</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>
<h4 id="read-older-versions-of-data">Read older versions of data</h4>
<p><strong>Delta Lake 提供方式查询历次数据更改后的数据版本的快照</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df1</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">versionAsOf</span><span class="sh">"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>

<span class="n">df2</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">timestampAsOf</span><span class="sh">"</span><span class="p">,</span> <span class="n">timestamp_string</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Data Retention</strong></p>

<p>为了访问先前版本的 Delta table 数据，必须完整地保留数据文件和事务日志。默认情况下，数据文件不会自动被清除，表的历史快照会被保留 30 天。</p>
<ol>
  <li>清除数据文件，执行 <a href="https://docs.delta.io/2.1.0/delta-utility.html#-delta-vacuum">VACUUM</a></li>
</ol>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- vacuum files not required by versions older than the default retention period</span>
<span class="k">VACUUM</span> <span class="p">{</span><span class="n">your_database</span><span class="p">}.</span><span class="n">delta_demo</span>

<span class="c1">-- vacuum files in path-based table</span>
<span class="k">VACUUM</span> <span class="s1">'/data/events'</span>
<span class="k">VACUUM</span> <span class="n">delta</span><span class="p">.</span><span class="nv">`/data/events/`</span>

<span class="c1">-- vacuum files not required by versions more than 100 hours old</span>
<span class="k">VACUUM</span> <span class="n">delta</span><span class="p">.</span><span class="nv">`/data/events/`</span> <span class="n">RETAIN</span> <span class="mi">100</span> <span class="n">HOURS</span>

<span class="c1">-- do dry run to get the list of files to be deleted</span>
<span class="k">VACUUM</span> <span class="p">{</span><span class="n">your_database</span><span class="p">}.</span><span class="n">delta_demo</span> <span class="n">DRY</span> <span class="n">RUN</span>
</code></pre></div></div>

<ol>
  <li>改变数据留存时间，改变 <a href="https://docs.delta.io/2.1.0/delta-batch.html#-table-properties">Table properties</a></li>
</ol>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">--controls how long the history for a table is kept. The default is interval 30 days.</span>
<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="p">{</span><span class="n">your_database</span><span class="p">}.</span><span class="n">delta_demo</span> <span class="k">SET</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="s1">'delta.logRetentionDuration'</span> <span class="o">=</span> <span class="s1">'interval &lt;interval&gt;'</span><span class="p">);</span>
</code></pre></div></div>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">--To access historical data even if you run VACUUM on the Delta table, This setting may cause your storage costs to go up.</span>
<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="p">{</span><span class="n">your_database</span><span class="p">}.</span><span class="n">delta_demo</span> <span class="k">SET</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="s1">'delta.deletedFileRetentionDuration'</span> <span class="o">=</span> <span class="s1">'interval &lt;interval&gt;'</span><span class="p">);</span>
</code></pre></div></div>

<h4 id="write-a-stream-of-data-to-a-table">Write a stream of data to a table</h4>
<p><strong>支持将 Structured Streaming 的流式数据集写入 Delta table</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">streamingDf</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">rate</span><span class="sh">"</span><span class="p">).</span><span class="nf">load</span><span class="p">()</span>

<span class="n">stream</span> <span class="o">=</span> <span class="n">streamingDf</span> \
  <span class="p">.</span><span class="nf">selectExpr</span><span class="p">(</span><span class="sh">"</span><span class="s">value as id</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">writeStream</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">checkpointLocation</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">/tmp/checkpoint</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">start</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="read-delta-table-as-a-streaming-source">Read Delta table as a streaming source</h4>
<p><strong>将 Delta 表的更新读进流式数据中</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stream2</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">writeStream</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">console</span><span class="sh">"</span><span class="p">)</span> \
  <span class="p">.</span><span class="nf">start</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="hive-insert-overwrite-vs-delta-lake-update">Hive Insert Overwrite VS Delta Lake Update</h3>
<h4 id="hive-insert-overwrite">Hive Insert Overwrite</h4>
<p><strong>Advantages:</strong></p>
<ol>
  <li><strong>Simplicity</strong>: Hive 的 overwrite 功能简单易用，特别是在需要完全替换表中数据时；</li>
  <li><strong>Compatibility</strong>: Hive 与 Hadoop 生态系统紧密集成，与各种基于 Hadoop 的工具和框架兼容；</li>
  <li><strong>Flexibility</strong>: 可以用于 overwrite 整个表或特定分区，提供数据管理的灵活性。</li>
</ol>

<p><strong>Disadvantages:</strong></p>
<ol>
  <li><strong>Limited Update Support</strong>: 缺乏细粒度更新的能力（如更新特定的行或列），对于细粒度更新的情景效率低下；</li>
  <li><strong>Resource-Intensive</strong>: overwrite 大表涉及删除现有数据并写入新数据，消耗大量资源，影响性能和存储利用率；</li>
  <li><strong>No Transaction Support</strong>: Hive 的 overwrite 操作不支持 ACID 事务，不利于在并发环境中保持数据完整性。</li>
</ol>

<h4 id="delta-lake-update">Delta Lake Update</h4>
<p><strong>Advantages:</strong></p>
<ol>
  <li><strong>ACID Transactions</strong>: Delta Lake 提供完整的 ACID 事务，确保在并发读写操作中数据的完整性和一致性；</li>
  <li><strong>Fine-Grained Updates</strong>: 支持细粒度更新，允许更高效和有针对性的数据操作；</li>
  <li><strong>Schema Evolution</strong>: Delta Lake 支持模式演化，允许对表 Schema 进行更改而无需重写整个数据集；</li>
  <li><strong>Optimized Performance</strong>: Delta Lake 的优化存储格式和事务功能有助于提高大规模数据集处理性能。</li>
</ol>

<p><strong>Disadvantages:</strong></p>
<ol>
  <li><strong>Dependency on Spark</strong>: Delta Lake 与 Apache Spark 紧密集成，受限于不能直接与其他数据处理框架一起使用；</li>
  <li><strong>Limited Compatibility</strong>: Delta Lake 与 Hive 的集成存在限制，主要在元数据管理方面；</li>
  <li><strong>Complexity</strong>: ACID 事务和模式演化功能增加了复杂性，需要更深入地理解底层存储和处理机制。</li>
</ol>

<h4 id="summary">Summary</h4>
<p>总之，Hive 的 overwrite 功能提供了简单性和兼容性，但缺乏细粒度更新支持和 ACID 事务；Delta Lake提供 ACID 事务、精细更新、模式演化和优化性能，但依赖于 Spark，与其他框架的兼容性有限。</p>

<p>具体的选择取决于用例的要求，包括对事务支持、精细更新和现有技术栈的需求。</p>

<h3 id="delta-lake-on-unstructured-and-semi-structured-data">Delta Lake on Unstructured and Semi-structured Data</h3>
<p>依照同样的原理，Delta Lake 也可以用来处理 Json、XML、Avro 等半结构化数据，以及文本、图像、音频、视频等非结构化的数据。</p>

<p><strong>1. 以 Json 数据为例，将半结构化对象存入 Delta Table</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="c1"># 创建 Spark Session
</span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span> \
    <span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">DeltaLakeExample</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.extensions</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">io.delta.sql.DeltaSparkSessionExtension</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.catalog.spark_catalog</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">org.apache.spark.sql.delta.catalog.DeltaCatalog</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">getOrCreate</span><span class="p">()</span>

<span class="c1"># 读取 JSON 数据
</span><span class="n">json_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">json</span><span class="p">(</span><span class="sh">"</span><span class="s">/path/to/json/files</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 将 JSON 数据写入 Delta Lake 表
</span><span class="n">json_df</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">append</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table-json</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 读取 Delta Lake 表中的 JSON 数据
</span><span class="n">delta_json_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table-json</span><span class="sh">"</span><span class="p">)</span>
<span class="n">delta_json_df</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><strong>2. 以文本数据为例，将非结构化对象存入 Delta Table</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="n">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># 创建 Spark Session
</span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span> \
    <span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">DeltaLakeExample</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.extensions</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">io.delta.sql.DeltaSparkSessionExtension</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.catalog.spark_catalog</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">org.apache.spark.sql.delta.catalog.DeltaCatalog</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">getOrCreate</span><span class="p">()</span>

<span class="c1"># 定义 schema
</span><span class="n">schema</span> <span class="o">=</span> <span class="nc">StructType</span><span class="p">([</span>
    <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">,</span> <span class="nc">IntegerType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
    <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># 创建数据
</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">This is a sample text.</span><span class="sh">"</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="sh">"</span><span class="s">Another example of text data.</span><span class="sh">"</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># 创建 DataFrame
</span><span class="n">text_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>

<span class="c1"># 将文本数据写入 Delta Lake 表
</span><span class="n">text_df</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">append</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table-text</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 读取 Delta Lake 表中的文本数据
</span><span class="n">delta_text_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/tmp/delta-table-text</span><span class="sh">"</span><span class="p">)</span>
<span class="n">delta_text_df</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p>To be continued…</p>]]></content><author><name></name></author><category term="go_big" /><summary type="html"><![CDATA[What is Delta Lake Delta Lake 是一个开源的数据湖存储层 (lakehouse storage layer) 技术，它利用基于文件的事务日志 (file-based transaction log) 扩展了 Parquet 数据文件，以实现 ACID 事务和可扩展的元数据处理。Delta Lake 与 Apache Spark API 完全兼容，专为与 Structured Streaming 集成而开发，可以很方便地对 batch &amp; streaming 数据进行处理。]]></summary></entry><entry><title type="html">Rules of AI in Cursor</title><link href="http://localhost:4000/blog/2024/09/17/rules_of_ai.html" rel="alternate" type="text/html" title="Rules of AI in Cursor" /><published>2024-09-17T00:00:00+08:00</published><updated>2024-09-17T00:00:00+08:00</updated><id>http://localhost:4000/blog/2024/09/17/rules_of_ai</id><content type="html" xml:base="http://localhost:4000/blog/2024/09/17/rules_of_ai.html"><![CDATA[<p>Here are the AI ​​answer rules I set for <a href="https://www.cursor.com/">Cursor</a> to help me maximize my learning and understanding of programming knowledge:</p>

<p>You are an Al coding instructor designed to assist and guide me as l learn to code. Your primary goal is to help me learn programming concepts, bestpractices, and problem-solving skils while writing code. Always assume l’m a beginner with limited programming knowledge.</p>

<p>Follow these guidelines in all interactions:</p>
<ol>
  <li>Explain concepts thoroughly but in simple terms, avoiding jargon when possible.</li>
  <li>When introducing new terms, provide clear definitions and examples.</li>
  <li>Break down complex problems into smaller,manageable steps.</li>
  <li>Encourage good coding practices and explain why they are important.</li>
  <li>Provide examples and analogies to illustrate programming concepts.</li>
  <li>Be patient and supportive, understanding that learning to code can be challenging.</li>
  <li>Offer praise for correct implementations and gentle corrections for mistakes.</li>
  <li>When correcting errors, explain why the error occurred and how to fix it.9.Suggest resources for further learning when appropriate</li>
  <li>Encourage me to ask questions and seek clarification.</li>
  <li>Foster problem-solving skils by guiding me to find solutions rather than always providing direct answers.</li>
  <li>Adapt your teaching style to my pace and learning preferences.</li>
  <li>Provide code snippets to illustrate concepts, but always explain the code line by line.</li>
  <li>Use comments throughout the code to help document what is happening.</li>
</ol>

<p>Address the my questions thoroughly, keeping in mind the quidelines above. lf the question is unclear or lacks context, ask me for clarification
Review the code and provide feedback. f there are erors or areas for improvement,explain them clearly and suggest corrections. if the code is correct, offerpraise and explain why it’s a good implementation.</p>

<p>Structure your responses as follows:</p>
<ol>
  <li>Format your response as markdown.</li>
  <li>Answer my question.</li>
  <li>Code review and feedback.</li>
  <li>Suggestions for further learning or practice.</li>
  <li>Using zh-CN.</li>
</ol>

<p>Remember, your goal is not just to help me write correct code, but to help me understand the underlying principles and develop my programming skilsAlways strive to be clear, patient, and encouraging in your responses.</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[Here are the AI ​​answer rules I set for Cursor to help me maximize my learning and understanding of programming knowledge:]]></summary></entry><entry><title type="html">Hands on Data Modeling</title><link href="http://localhost:4000/go_big/2024/09/17/data_modeling.html" rel="alternate" type="text/html" title="Hands on Data Modeling" /><published>2024-09-17T00:00:00+08:00</published><updated>2024-09-17T00:00:00+08:00</updated><id>http://localhost:4000/go_big/2024/09/17/data_modeling</id><content type="html" xml:base="http://localhost:4000/go_big/2024/09/17/data_modeling.html"><![CDATA[<h3 id="what-is-data-modeling">What is Data Modeling</h3>
<p>数据建模是指创建数据模型的过程。软件工程中，数据工程师在设计数据库时，会将现实世界的各类数据及其关系进行分析、抽象，从中找出内在联系，并将其形式化描述为数据模型，以此建立信息系统的数据库结构。</p>

<h3 id="why-data-modeling">Why Data Modeling</h3>
<ol>
  <li>帮助理解和组织数据，使其更易于管理和使用；</li>
  <li>通过优化数据结构，提高数据存储和检索的效率；</li>
  <li>定义数据的约束和规则，确保数据的一致性和完整性；</li>
  <li>确保数据模型能够满足业务需求和流程。</li>
</ol>

<h3 id="how-to-model-data">How to Model Data</h3>
<ol>
  <li>Requirement Analysis
    <ul>
      <li>定义和分析业务需求；</li>
      <li>确定数据需求和需要的相应支持。</li>
    </ul>
  </li>
  <li>Conceptual Data Model
    <ul>
      <li>定义实体以及实体之间的关系；</li>
      <li>使用 ER(Entity-relationship) 图来表示数据的高层次结构，常用 <a href="https://www.lucidchart.com/pages/?">Lucidchart</a> 来构建概念模型。</li>
    </ul>
  </li>
  <li>Logical Data Model
    <ul>
      <li>在概念模型的基础上添加更多信息，定义表、列、主键和外键；</li>
      <li>一个概念模型的实现可能需要多个逻辑模型。</li>
    </ul>
  </li>
  <li>Physical Data Model
    <ul>
      <li>根据逻辑模型创建数据库对象，包括数据表的物理位置、物理名字、字段类型以及命名规范；</li>
      <li>考虑数据库的性能、存储和索引。</li>
    </ul>
  </li>
</ol>

<h3 id="data-warehouse">Data Warehouse</h3>
<p>数据仓库 (Data Warehouse) 是一个用于存储和分析大量数据的系统，它通常从多个源系统中提取数据，并进行清洗、转换和加载 (ETL) 供数据分析和 BI 报告使用。数据建模在数据仓库的构建过程中同样尤为重要。</p>

<h4 id="数据仓库建模的类型">数据仓库建模的类型</h4>
<ol>
  <li>Star Schema
    <ul>
      <li>星型模型 (Star Schema) 以事实表 (Fact Table) 为中心，周围是维度表 (Dimension Table)；</li>
      <li>事实表存储度量数据（如: 销售额），维度表存储描述数据（如: 时间、地点、产品）。</li>
    </ul>
  </li>
  <li>Snowflake Schema
    <ul>
      <li>雪花模型 (Snowflake Schema) 是星型模型的扩展，将维度表进一步规范化，分解成多个相关的表；</li>
      <li>它的特点是减少了数据冗余，但是提高了查询的复杂性。</li>
    </ul>
  </li>
  <li>Constellation Schema
    <ul>
      <li>事实星座模型 (Fact Constellation Schema) 包含多个事实表，适用于复杂的业务场景。</li>
    </ul>
  </li>
</ol>

<h3 id="data-lake">Data Lake</h3>
<p>数据湖 (Data Lake) 和数据仓库一样，是存储大量数据的系统，但数据湖不仅用于存储结构化数据，还用来存储半结构化、非结构化数据。数据湖允许以原始格式存储数据，数据的质量和一致性可能较低。它一般用于存储用户行为数据，如网站日志、社交媒体数据、视频等，以进行大数据分析和机器学习。</p>

<h3 id="data-lakehouse">Data Lakehouse</h3>
<p>数据湖仓库 (Data Lakehouse) 结合了数据湖和数据仓库的优点，它既能处理结构化数据，也能处理非结构化数据，同时提供了高效的查询性能和数据管理功能。它的代表产品是由 <a href="https://docs.databricks.com/en/delta/index.html">Databricks</a> 开发的基于 Apache Spark 的开源存储层的 <a href="https://delta.io/">Delta Lake</a>，以及用于大规模数据集的高性能表格式的 <a href="https://iceberg.apache.org/">Apache Iceberg</a>。</p>

<p>关于 Delta Lake 可以参见我的这一篇日志：<a href="../19/delta_lake.html">Delta Lake</a>.</p>

<h3 id="数据建模过程中常见问题及应对措施">数据建模过程中常见问题及应对措施</h3>
<blockquote>
  <p><strong>Problem</strong>: 业务需求不清晰，以及项目进行中需求变更频繁</p>

  <p><strong>Solution</strong>:</p>
  <ol>
    <li>深入沟通，明确需求，并编写详细的需求文档；</li>
    <li>采用迭代开发的方法，分阶段完善数据模型</li>
  </ol>
</blockquote>

<blockquote>
  <p><strong>Problem</strong>: 不同数据源数据不一致，数据缺失，数据冗余</p>

  <p><strong>Solution</strong>:</p>
  <ol>
    <li>数据清洗，确保数据的一致性和完整性；</li>
    <li>建立数据验证规则，确保数据的准确性</li>
  </ol>
</blockquote>

<blockquote>
  <p><strong>Problem</strong>: 实体之间关系复杂，数据模型复杂</p>

  <p><strong>Solution</strong>:</p>
  <ol>
    <li>以目的驱动简化模型，避免不必要的复杂度；</li>
    <li>将复杂的数据模型分解为多个模块，分别建模和管理</li>
  </ol>
</blockquote>

<blockquote>
  <p><strong>Problem</strong>: 存储效率低，查询性能差</p>

  <p><strong>Solution</strong>:</p>
  <ol>
    <li>根据实际需求，平衡数据的 Normalization 和 Denormalization；</li>
    <li>为常用查询字段建立索引；</li>
    <li>在数据建模过程中进行性能测试</li>
  </ol>

  <blockquote>
    <p><em>注：</em></p>

    <p><em>1.规范化（Normalization）：规范化是将数据组织成多个相关表的过程，以减少数据冗余和提高数据一致性；</em></p>

    <p><em>2.反规范化（Denormalization）：反规范化是将数据合并到较少的表中，以减少查询时的多表连接，从而提高查询性能</em></p>
  </blockquote>
</blockquote>

<blockquote>
  <p><strong>Problem</strong>: 敏感数据泄露</p>

  <p><strong>Solution</strong>:</p>
  <ol>
    <li>对敏感数据进行加密；</li>
    <li>严格的访问控制策略，确保只有授权的用户可以访问数据</li>
  </ol>
</blockquote>

<p>To be continued…</p>]]></content><author><name></name></author><category term="go_big" /><summary type="html"><![CDATA[What is Data Modeling 数据建模是指创建数据模型的过程。软件工程中，数据工程师在设计数据库时，会将现实世界的各类数据及其关系进行分析、抽象，从中找出内在联系，并将其形式化描述为数据模型，以此建立信息系统的数据库结构。]]></summary></entry></feed>